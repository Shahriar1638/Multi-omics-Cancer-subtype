{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6b0332",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "751acfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508448c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: (60660, 247)\n",
      "Methylation: (212382, 247)\n",
      "Copy Number: (56756, 247)\n",
      "Protein: (457, 211)\n",
      "Phenotype: (210, 79)\n",
      "Phenotype: (13, 2)\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "expression_data_scaled=pd.read_csv(\"processed_expression.csv\")\n",
    "methylation_scaled=pd.read_csv(\"processed_methylation.csv\")\n",
    "copy_number_scaled=pd.read_csv(\"processed_cnv.csv\")\n",
    "protein_scaled=pd.read_csv(\"processed_protein.csv\")\n",
    "phenotype_data_cleaned=pd.read_csv(\"processed_phenotype.csv\")\n",
    "subtype_mapping=pd.read_csv(\"subtype_mapping_with_protein.csv\")\n",
    "subtype_labels = pd.read_csv(\"subtype_labels.csv\")\n",
    "print(\"Expression:\", expression_data_scaled.shape)\n",
    "print(\"Methylation:\", methylation_scaled.shape)\n",
    "print(\"Copy Number:\", copy_number_scaled.shape)\n",
    "print(\"Protein:\", protein_scaled.shape)\n",
    "print(\"Phenotype:\", phenotype_data_cleaned.shape)\n",
    "print(\"Phenotype:\", subtype_mapping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2832e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ensembl_ID  TCGA-DX-AB2O-01A  TCGA-IS-A3K7-01A  TCGA-DX-A7EQ-01A  \\\n",
      "0  ENSG00000000003.15         -1.152830         -0.219623         -0.884881   \n",
      "1   ENSG00000000005.6          0.330547         -1.014041         -0.763520   \n",
      "2  ENSG00000000419.13         -0.213944         -0.593653         -4.090048   \n",
      "3  ENSG00000000457.14          0.822442         -1.529460         -2.880470   \n",
      "4  ENSG00000000460.17          1.047877         -1.004992         -4.226427   \n",
      "\n",
      "   TCGA-FX-A48G-01A  \n",
      "0         -0.526559  \n",
      "1          0.378398  \n",
      "2         -3.689964  \n",
      "3         -2.294075  \n",
      "4         -3.340772  \n",
      "  Composite Element REF  TCGA-DX-AB2O-01A  TCGA-IS-A3K7-01A  TCGA-DX-A7EQ-01A  \\\n",
      "0            cg00000165          1.499566         -0.235202         -1.133312   \n",
      "1            cg00000292          0.303039          0.485554         -1.261731   \n",
      "2            cg00000321         -1.374888         -0.928886         -0.113112   \n",
      "3            cg00000363         -0.540672          0.649121         -0.672558   \n",
      "4            cg00000924         -0.082429          1.021803         -1.946780   \n",
      "\n",
      "   TCGA-FX-A48G-01A  \n",
      "0         -0.154807  \n",
      "1          0.873418  \n",
      "2          0.351712  \n",
      "3         -0.861232  \n",
      "4          0.753221  \n",
      "           Ensembl_ID  TCGA-DX-AB2O-01A  TCGA-IS-A3K7-01A  TCGA-DX-A7EQ-01A  \\\n",
      "0  ENSG00000230021.10          1.244408         -0.419312         -0.419312   \n",
      "1  ENSG00000237491.10          1.265492         -0.417270         -0.417270   \n",
      "2   ENSG00000230092.7          1.244408         -0.419312         -0.419312   \n",
      "3   ENSG00000177757.2          1.244408         -0.419312         -0.419312   \n",
      "4  ENSG00000228794.10          1.241048         -0.422700         -0.422700   \n",
      "\n",
      "   TCGA-FX-A48G-01A  \n",
      "0         -1.251172  \n",
      "1         -1.258651  \n",
      "2         -1.251172  \n",
      "3         -1.251172  \n",
      "4         -1.254575  \n",
      "  peptide_target  TCGA-MB-A5Y8-01A  TCGA-SI-AA8C-01A  TCGA-X6-A8C4-01A  \\\n",
      "0       1433BETA         -0.609370          0.080669          0.024874   \n",
      "1    1433EPSILON          1.800678         -0.072747         -0.367460   \n",
      "2       1433ZETA          0.882075          0.516539          0.745134   \n",
      "3          4EBP1          0.295574          0.259058          0.767892   \n",
      "4     4EBP1_pS65         -0.604365          0.210249         -0.217806   \n",
      "\n",
      "   TCGA-DX-AB3A-01A  \n",
      "0          0.285082  \n",
      "1         -0.881580  \n",
      "2         -1.035655  \n",
      "3         -0.167595  \n",
      "4         -1.502091  \n",
      "             sample                                    id  \\\n",
      "0  TCGA-DX-A6B9-01A  cc891960-42a2-4d76-b93b-c2914c929154   \n",
      "1  TCGA-DX-A8BR-01A  5452ffd8-0408-4a78-b2fd-f1e0b0d05276   \n",
      "2  TCGA-DX-A1L3-01A  9517413b-b5b8-4130-8ba1-d86d44abe2ec   \n",
      "3  TCGA-Z4-AAPF-01A  e0b298e0-0d11-4cc8-a9fa-7f2cc9f1d6e9   \n",
      "4  TCGA-DX-A7ET-01A  47a0e4a8-140f-475c-878d-8e03df3f82de   \n",
      "\n",
      "                           disease_type                               case_id  \\\n",
      "0                   Myomatous Neoplasms  cc891960-42a2-4d76-b93b-c2914c929154   \n",
      "1                 Fibromatous Neoplasms  5452ffd8-0408-4a78-b2fd-f1e0b0d05276   \n",
      "2                  Lipomatous Neoplasms  9517413b-b5b8-4130-8ba1-d86d44abe2ec   \n",
      "3               Synovial-like Neoplasms  e0b298e0-0d11-4cc8-a9fa-7f2cc9f1d6e9   \n",
      "4  Soft Tissue Tumors and Sarcomas, NOS  47a0e4a8-140f-475c-878d-8e03df3f82de   \n",
      "\n",
      "   submitter_id  \n",
      "0  TCGA-DX-A6B9  \n",
      "1  TCGA-DX-A8BR  \n",
      "2  TCGA-DX-A1L3  \n",
      "3  TCGA-Z4-AAPF  \n",
      "4  TCGA-DX-A7ET  \n",
      "                       subtype_name  encoded_label\n",
      "0      Dedifferentiated liposarcoma              0\n",
      "1                  Fibromyxosarcoma              1\n",
      "2                Giant cell sarcoma              2\n",
      "3               Leiomyosarcoma, NOS              3\n",
      "4  Liposarcoma, well differentiated              4\n"
     ]
    }
   ],
   "source": [
    "print(expression_data_scaled.iloc[:5, :5])  # First 5 rows/columns\n",
    "print(methylation_scaled.iloc[:5, :5])\n",
    "print(copy_number_scaled.iloc[:5, :5])\n",
    "print(protein_scaled.iloc[:5, :5])\n",
    "print(phenotype_data_cleaned.iloc[:5, :5])\n",
    "print(subtype_mapping.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6c57be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes after setting index:\n",
      "  Expression: (60660, 246)\n",
      "  Methylation: (212382, 246)\n",
      "  Copy number: (56756, 246)\n",
      "  Protein: (457, 210)\n",
      "  Phenotype: (210, 78)\n",
      "Sample overlap:\n",
      "Expression samples: 246\n",
      "Methylation samples: 246\n",
      "CNV samples: 246\n",
      "Protein samples: 210\n",
      "Clinical samples: 210\n",
      "Common samples across all omics: 210\n",
      "Samples after removing missing subtypes: 210\n",
      "\n",
      "Subtype encoding mapping:\n",
      "  0: Dedifferentiated liposarcoma\n",
      "  1: Fibromyxosarcoma\n",
      "  2: Giant cell sarcoma\n",
      "  3: Leiomyosarcoma, NOS\n",
      "  4: Liposarcoma, well differentiated\n",
      "  5: Malignant fibrous histiocytoma\n",
      "  6: Malignant peripheral nerve sheath tumor\n",
      "  7: Myxoid leiomyosarcoma\n",
      "  8: Pleomorphic liposarcoma\n",
      "  9: Synovial sarcoma, NOS\n",
      "  10: Synovial sarcoma, biphasic\n",
      "  11: Synovial sarcoma, spindle cell\n",
      "  12: Undifferentiated sarcoma\n",
      "\n",
      "Encoded subtype distribution:\n",
      "subtype_encoded\n",
      "0     49\n",
      "1     20\n",
      "2      3\n",
      "3     76\n",
      "4      1\n",
      "5     11\n",
      "6      9\n",
      "7      1\n",
      "8      2\n",
      "9      1\n",
      "10     1\n",
      "11     4\n",
      "12    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final data shapes after phenotype preprocessing:\n",
      "  Expression: (60660, 210)\n",
      "  Methylation: (212382, 210)\n",
      "  Copy number: (56756, 210)\n",
      "  Protein: (457, 210)\n",
      "  Phenotype: (210, 78)\n",
      "  Subtypes: 210\n",
      "  Common samples: 210\n",
      "\n",
      "Final data shapes after phenotype preprocessing:\n",
      "  Expression: (60660, 210)\n",
      "  Methylation: (212382, 210)\n",
      "  Copy number: (56756, 210)\n",
      "  Protein: (457, 210)\n",
      "  Phenotype: (210, 78)\n",
      "  Subtypes: 210\n",
      "  Common samples: 210\n"
     ]
    }
   ],
   "source": [
    "# Fix data indexing first - set the first column as index for each omics data\n",
    "expression_data_scaled = expression_data_scaled.set_index(expression_data_scaled.columns[0])\n",
    "methylation_scaled = methylation_scaled.set_index(methylation_scaled.columns[0])\n",
    "copy_number_scaled = copy_number_scaled.set_index(copy_number_scaled.columns[0])\n",
    "protein_scaled = protein_scaled.set_index(protein_scaled.columns[0])\n",
    "phenotype_data_cleaned = phenotype_data_cleaned.set_index(phenotype_data_cleaned.columns[0])\n",
    "\n",
    "print(\"Data shapes after setting index:\")\n",
    "print(f\"  Expression: {expression_data_scaled.shape}\")\n",
    "print(f\"  Methylation: {methylation_scaled.shape}\")\n",
    "print(f\"  Copy number: {copy_number_scaled.shape}\")\n",
    "print(f\"  Protein: {protein_scaled.shape}\")\n",
    "print(f\"  Phenotype: {phenotype_data_cleaned.shape}\")\n",
    "\n",
    "# Sample matching\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "\n",
    "# Get sample sets from each omics type\n",
    "samples_expression = set(expression_data_scaled.columns)\n",
    "samples_methylation = set(methylation_scaled.columns)\n",
    "samples_cnv = set(copy_number_scaled.columns)\n",
    "samples_protein = set(protein_scaled.columns)\n",
    "samples_clinical = set(phenotype_data_cleaned.index)\n",
    "\n",
    "print(\"Sample overlap:\")\n",
    "print(f\"Expression samples: {len(samples_expression)}\")\n",
    "print(f\"Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"Protein samples: {len(samples_protein)}\")\n",
    "print(f\"Clinical samples: {len(samples_clinical)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_protein, samples_clinical))\n",
    "print(f\"Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Extract subtypes for the common samples\n",
    "subtypes = phenotype_data_cleaned.loc[common_samples, subtype_column]\n",
    "\n",
    "# Remove any samples with missing subtypes\n",
    "subtypes_clean = subtypes.dropna()\n",
    "final_samples = list(subtypes_clean.index)\n",
    "\n",
    "print(f\"Samples after removing missing subtypes: {len(final_samples)}\")\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes_clean)\n",
    "\n",
    "# Create mapping to encode subtype classes\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"\\nSubtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"  {encoded}: {subtype}\")\n",
    "\n",
    "# Convert to pandas Series\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes_clean.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nEncoded subtype distribution:\")\n",
    "print(subtype_encoded.value_counts().sort_index())\n",
    "\n",
    "# Filter all omics data to final common samples\n",
    "expression_data_scaled = expression_data_scaled[final_samples]\n",
    "methylation_scaled = methylation_scaled[final_samples]\n",
    "copy_number_scaled = copy_number_scaled[final_samples]\n",
    "protein_scaled = protein_scaled[final_samples]\n",
    "\n",
    "common_samples = final_samples\n",
    "print()\n",
    "print(f\"Final data shapes after phenotype preprocessing:\")\n",
    "print(f\"  Expression: {expression_data_scaled.shape}\")\n",
    "print(f\"  Methylation: {methylation_scaled.shape}\")\n",
    "print(f\"  Copy number: {copy_number_scaled.shape}\")\n",
    "print(f\"  Protein: {protein_scaled.shape}\")\n",
    "print(f\"  Phenotype: {phenotype_data_cleaned.shape}\")\n",
    "print(f\"  Subtypes: {len(subtype_encoded)}\")\n",
    "print(f\"  Common samples: {len(common_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e74e97",
   "metadata": {},
   "source": [
    "# Reduce Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004490f",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c2edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing models...\n",
      "============================================================\n",
      "INITIALIZING AUTOENCODERS\n",
      "============================================================\n",
      "\n",
      ">> Processing expr modality\n",
      "   Data shape: (60660, 210) -> After transpose: torch.Size([210, 60660])\n",
      "   Input dimension (features): 60660\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 60660)\n",
      "\n",
      ">> Processing meth modality\n",
      "   Data shape: (212382, 210) -> After transpose: torch.Size([210, 212382])\n",
      "   Input dimension (features): 212382\n",
      "   Data shape: (212382, 210) -> After transpose: torch.Size([210, 212382])\n",
      "   Input dimension (features): 212382\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 212382)\n",
      "\n",
      ">> Processing cnv modality\n",
      "   Data shape: (56756, 210) -> After transpose: torch.Size([210, 56756])\n",
      "   Input dimension (features): 56756\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 56756)\n",
      "\n",
      ">> Processing prot modality\n",
      "   Data shape: (457, 210) -> After transpose: torch.Size([210, 457])\n",
      "   Input dimension (features): 457\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 457)\n",
      "\n",
      "============================================================\n",
      "AUTOENCODER INITIALIZATION COMPLETE\n",
      "============================================================\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 212382)\n",
      "\n",
      ">> Processing cnv modality\n",
      "   Data shape: (56756, 210) -> After transpose: torch.Size([210, 56756])\n",
      "   Input dimension (features): 56756\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 56756)\n",
      "\n",
      ">> Processing prot modality\n",
      "   Data shape: (457, 210) -> After transpose: torch.Size([210, 457])\n",
      "   Input dimension (features): 457\n",
      "   ✓ Bottleneck shape: (210, 64)\n",
      "   ✓ Decoder shape: (210, 457)\n",
      "\n",
      "============================================================\n",
      "AUTOENCODER INITIALIZATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, latent_dim=64):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)  # Bottleneck representation\n",
    "        x_hat = self.decoder(z)  # Decoder representation\n",
    "        return x_hat, z\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Extract bottleneck representation\"\"\"\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Extract decoder representation\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "def extract_representations(model, tensor_data):\n",
    "    \"\"\"Extract bottleneck and decoder representations from trained autoencoder\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get bottleneck (latent) representation\n",
    "        bottleneck = model.encode(tensor_data)\n",
    "        # Get decoder representation (reconstructed features)\n",
    "        decoder_repr = model.decode(bottleneck)\n",
    "    return bottleneck.cpu().numpy(), decoder_repr.cpu().numpy()\n",
    "\n",
    "# Initialize autoencoders for each omics type (without training)\n",
    "omics_scaled = {\n",
    "    'expr': expression_data_scaled,\n",
    "    'meth': methylation_scaled,\n",
    "    'cnv': copy_number_scaled,\n",
    "    'prot': protein_scaled\n",
    "}\n",
    "\n",
    "# Store autoencoder models (to be trained later)\n",
    "autoencoder_models = {}\n",
    "bottleneck_embeds = {}\n",
    "decoder_embeds = {}\n",
    "\n",
    "for name, df in omics_scaled.items():\n",
    "    print(f\">> Initializing autoencoder for {name} modality\")\n",
    "\n",
    "    X = torch.tensor(df.values.T, dtype=torch.float32, device=device)  # (samples, features) -- Transpose to (features, samples)\n",
    "    input_dim = X.shape[1]\n",
    "    sample_ids = df.columns\n",
    "    \n",
    "    print(f\"Data shape: {df.shape} -> After transpose: {X.shape}\")\n",
    "    print(f\"Input dimension (features): {input_dim}\")\n",
    "    \n",
    "    # Initialize autoencoder\n",
    "    model = Autoencoder(\n",
    "        input_dim=input_dim, \n",
    "        hidden_dim=128,\n",
    "        latent_dim=64\n",
    "    ).to(device)\n",
    "    autoencoder_models[name] = model\n",
    "\n",
    "    bottleneck, decoder_repr = extract_representations(model, X)\n",
    "    \n",
    "    print(f\"Index colomn shape: {df.columns.shape}\")\n",
    "    bottleneck_embeds[name] = pd.DataFrame(\n",
    "        bottleneck,\n",
    "        index=sample_ids,  # Sample IDs\n",
    "        columns=[f\"{name}_bottleneck_{i}\" for i in range(bottleneck.shape[1])]\n",
    "    )\n",
    "    \n",
    "    print(f\"Index colomn shape: {df.columns.shape}\")\n",
    "    decoder_embeds[name] = pd.DataFrame(\n",
    "        decoder_repr,\n",
    "        index=sample_ids,  # Sample IDs\n",
    "        columns=[f\"{name}_decoder_{i}\" for i in range(decoder_repr.shape[1])]\n",
    "    )\n",
    "    \n",
    "    print(f\"   Bottleneck shape: {bottleneck_embeds[name].shape}\")\n",
    "    print(f\"   Decoder shape: {decoder_embeds[name].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e45d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create fusion models\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Creating Fusion Models\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# # Fusion Model 1: Using bottleneck representations\n",
    "# bottleneck_fusion = pd.concat(\n",
    "#     [bottleneck_embeds['expr'], bottleneck_embeds['meth'], \n",
    "#      bottleneck_embeds['cnv'], bottleneck_embeds['prot']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Fusion Model 2: Using decoder representations\n",
    "# decoder_fusion = pd.concat(\n",
    "#     [decoder_embeds['expr'], decoder_embeds['meth'], \n",
    "#      decoder_embeds['cnv'], decoder_embeds['prot']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# print(f\"Bottleneck fusion shape: {bottleneck_fusion.shape}\")\n",
    "# print(f\"Decoder fusion shape: {decoder_fusion.shape}\")\n",
    "\n",
    "# print(\"\\nFusion models created successfully!\")\n",
    "# print(\"Note: These use untrained autoencoders. Train the models first, then re-extract representations.\")\n",
    "\n",
    "# # Display sample data\n",
    "# print(f\"\\nBottleneck fusion sample:\")\n",
    "# print(bottleneck_fusion.head())\n",
    "\n",
    "# print(f\"\\nDecoder fusion sample:\")\n",
    "# print(decoder_fusion.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
