{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2844558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0+cu129\n",
      "Device available: CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c4bc7",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load raw TCGA-SARC multi-omics datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17edada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TCGA-SARC multi-omics datasets...\n",
      "==================================================\n",
      "Raw data shapes:\n",
      "ğŸ“Š Expression data: (60660, 265) (genes x samples)\n",
      "ğŸ§¬ Methylation data: (486427, 269) (CpG sites x samples)\n",
      "ğŸ“ˆ Copy number data: (60623, 248) (genes x samples)\n",
      "ğŸ¥ Clinical data: (272, 78) (samples x features)\n",
      "\n",
      "âœ… Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading TCGA-SARC multi-omics datasets...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load multi-omics data\n",
    "expression_data = pd.read_csv('../TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('../TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('../TCGA-SARC.gene-level_absolute.tsv', sep='\\t', index_col=0) # Copy number variations (absolute)\n",
    "\n",
    "# Load clinical data with error handling\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Initial load failed ({e}), attempting with error handling...\")\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Raw data shapes:\")\n",
    "print(f\"ğŸ“Š Expression data: {expression_data.shape} (genes x samples)\")\n",
    "print(f\"ğŸ§¬ Methylation data: {methylation_data.shape} (CpG sites x samples)\")\n",
    "print(f\"ğŸ“ˆ Copy number data: {copy_number_data.shape} (genes x samples)\")\n",
    "print(f\"ğŸ¥ Clinical data: {phenotype_data.shape} (samples x features)\")\n",
    "\n",
    "print(\"\\nâœ… Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc85cc0",
   "metadata": {},
   "source": [
    "## 3. Sample Matching & Quality Control\n",
    "Identify common samples across all omics platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acea1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample matching and quality assessment...\n",
      "==================================================\n",
      "Sample counts per modality:\n",
      "ğŸ§¬ Expression samples: 265\n",
      "ğŸ”¬ Methylation samples: 269\n",
      "ğŸ“Š CNV samples: 248\n",
      "ğŸ¥ Clinical samples: 272\n",
      "\n",
      "ğŸ¯ Common samples across all omics: 246\n",
      "\n",
      "ğŸ“ Filtered data shapes:\n",
      "Expression: (60660, 246)\n",
      "Methylation: (486427, 246)\n",
      "Copy Number: (60623, 246)\n",
      "Clinical: (246, 78)\n",
      "\n",
      "âœ… Sample matching completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample matching and quality assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check sample overlap between different omics data\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "\n",
    "print(\"Sample counts per modality:\")\n",
    "print(f\"ğŸ§¬ Expression samples: {len(samples_expression)}\")\n",
    "print(f\"ğŸ”¬ Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"ğŸ“Š CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"ğŸ¥ Clinical samples: {len(samples_clinical)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical))\n",
    "print(f\"\\nğŸ¯ Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]\n",
    "\n",
    "print(f\"\\nğŸ“ Filtered data shapes:\")\n",
    "print(f\"Expression: {expression_data.shape}\")\n",
    "print(f\"Methylation: {methylation_data.shape}\")\n",
    "print(f\"Copy Number: {copy_number_data.shape}\")\n",
    "print(f\"Clinical: {phenotype_data.shape}\")\n",
    "\n",
    "print(\"\\nâœ… Sample matching completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5784a6",
   "metadata": {},
   "source": [
    "## 4. Missing Value Assessment\n",
    "Comprehensive analysis of missing values across all omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fce29fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value assessment...\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Expression Data:\n",
      "   Total values: 14,922,360\n",
      "   Missing values: 0\n",
      "   Missing percentage: 0.00%\n",
      "   âœ… No missing values found\n",
      "\n",
      "ğŸ“Š Methylation Data:\n",
      "   Total values: 119,661,042\n",
      "   Missing values: 19,622,910\n",
      "   Missing percentage: 16.40%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“Š Copy Number Data:\n",
      "   Total values: 14,913,258\n",
      "   Missing values: 994,360\n",
      "   Missing percentage: 6.67%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“Š Phenotype Data:\n",
      "   Total values: 19,188\n",
      "   Missing values: 3,960\n",
      "   Missing percentage: 20.64%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“‹ MISSING VALUE SUMMARY:\n",
      "Expression: 0 (0.00%)\n",
      "Methylation: 19,622,910 (16.40%)\n",
      "Copy Number: 994,360 (6.67%)\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Phenotype: 3,960 (20.64%)\n",
      "\n",
      "âœ… Missing value assessment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for null values in each omics modality\n",
    "def assess_missing_values(data, name):\n",
    "    total_values = data.size\n",
    "    missing_count = data.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / total_values) * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {name}:\")\n",
    "    print(f\"   Total values: {total_values:,}\")\n",
    "    print(f\"   Missing values: {missing_count:,}\")\n",
    "    print(f\"   Missing percentage: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"   âš ï¸  Contains missing values - preprocessing required\")\n",
    "    else:\n",
    "        print(f\"   âœ… No missing values found\")\n",
    "    \n",
    "    return missing_count, missing_percentage\n",
    "\n",
    "# Assess each omics modality\n",
    "expr_missing, expr_pct = assess_missing_values(expression_data, \"Expression Data\")\n",
    "meth_missing, meth_pct = assess_missing_values(methylation_data, \"Methylation Data\")\n",
    "cnv_missing, cnv_pct = assess_missing_values(copy_number_data, \"Copy Number Data\")\n",
    "pheno_missing, pheno_pct = assess_missing_values(phenotype_data, \"Phenotype Data\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nğŸ“‹ MISSING VALUE SUMMARY:\")\n",
    "print(f\"Expression: {expr_missing:,} ({expr_pct:.2f}%)\")\n",
    "print(f\"Methylation: {meth_missing:,} ({meth_pct:.2f}%)\")\n",
    "print(f\"Copy Number: {cnv_missing:,} ({cnv_pct:.2f}%)\")\n",
    "max_value = copy_number_data.max().max()\n",
    "min_value = copy_number_data.min().min()\n",
    "\n",
    "print(f\"Maximum CNV value: {max_value}\")\n",
    "print(f\"Minimum CNV value: {min_value}\")\n",
    "print()\n",
    "print(f\"Phenotype: {pheno_missing:,} ({pheno_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Missing value assessment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Log2 transform\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "# Methylation data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Drop probes with more than 20% missing values\n",
    "methylation_data = methylation_data.dropna(thresh=0.8 * methylation_data.shape[1], axis=0)\n",
    "\n",
    "# Fill NA with probe-wise median\n",
    "methylation_data = methylation_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "# Clip beta values to avoid log(0) or log(inf)\n",
    "# Add small offset to prevent numerical issues\n",
    "epsilon = 1e-6\n",
    "methylation_clipped = methylation_data.clip(lower=epsilon, upper=1-epsilon)\n",
    "\n",
    "# Convert to M-values: M = log2(Beta / (1 - Beta))\n",
    "methylation_m_values = np.log2(methylation_clipped / (1 - methylation_clipped))\n",
    "\n",
    "# Remove low-variance probes\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_scaled = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_m_values.T).T,\n",
    "    index=methylation_m_values.index[selector.get_support()],\n",
    "    columns=methylation_m_values.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Copy number data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Handle missing values\n",
    "gene_missing_threshold = 0.2\n",
    "cnv_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "cnv_imputed = cnv_filtered.apply(lambda row: row.fillna(row.median()), axis=1)\n",
    "\n",
    "# Remove low-variance regions (RECOMMENDED for PCA)\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "cnv_variable = pd.DataFrame(\n",
    "    selector.fit_transform(cnv_imputed.T).T,\n",
    "    index=cnv_imputed.index[selector.get_support()],\n",
    "    columns=cnv_imputed.columns\n",
    ")\n",
    "removed = cnv_imputed.shape[0] - cnv_variable.shape[0]\n",
    "\n",
    "scaler_cnv = StandardScaler()\n",
    "copy_number_scaled = pd.DataFrame(\n",
    "    scaler_cnv.fit_transform(cnv_variable.T).T,\n",
    "    index=cnv_variable.index,\n",
    "    columns=cnv_variable.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c52b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Phenotype Data...\n",
      "==================================================\n",
      "ğŸ¯ Target column: 'primary_diagnosis.diagnoses'\n",
      "ğŸ“Š Original subtype distribution:\n",
      "   âœ… Leiomyosarcoma, NOS: 96\n",
      "   âœ… Dedifferentiated liposarcoma: 53\n",
      "   âœ… Undifferentiated sarcoma: 34\n",
      "   âœ… Fibromyxosarcoma: 22\n",
      "\n",
      "ğŸ”„ Filtering to selected subtypes...\n",
      "ğŸ“Š Removed 0 samples (0.0%)\n",
      "ğŸ“Š Remaining samples: 205\n",
      "\n",
      "ğŸ” Missing values in subtype column: 0\n",
      "âœ… No missing subtypes found\n",
      "ğŸ“Š Clean phenotype data shape: (205, 78)\n",
      "\n",
      "ğŸ”„ Encoding subtypes as numeric labels...\n",
      "ğŸ“‹ Subtype encoding mapping:\n",
      "   0: Dedifferentiated liposarcoma\n",
      "   1: Fibromyxosarcoma\n",
      "   2: Leiomyosarcoma, NOS\n",
      "   3: Undifferentiated sarcoma\n",
      "\n",
      "ğŸ“Š Encoded subtype distribution:\n",
      "   Class 0: 53 samples (Dedifferentiated liposarcoma)\n",
      "   Class 1: 22 samples (Fibromyxosarcoma)\n",
      "   Class 2: 96 samples (Leiomyosarcoma, NOS)\n",
      "   Class 3: 34 samples (Undifferentiated sarcoma)\n",
      "\n",
      "âœ… Phenotype data processing completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Phenotype Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define subtype column and selected subtypes\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "selected_subtypes = [\n",
    "    'Leiomyosarcoma, NOS',\n",
    "    'Dedifferentiated liposarcoma',\n",
    "    'Undifferentiated sarcoma',\n",
    "    'Fibromyxosarcoma'\n",
    "]\n",
    "\n",
    "print(f\"ğŸ¯ Target column: '{subtype_column}'\")\n",
    "print(f\"ğŸ“Š Original subtype distribution:\")\n",
    "subtype_counts = phenotype_data[subtype_column].value_counts()\n",
    "for subtype, count in subtype_counts.items():\n",
    "    marker = \"âœ…\" if subtype in selected_subtypes else \"âŒ\"\n",
    "    print(f\"   {marker} {subtype}: {count}\")\n",
    "\n",
    "# Filter to selected subtypes only\n",
    "print(f\"\\nğŸ”„ Filtering to selected subtypes...\")\n",
    "before_filter = len(phenotype_data)\n",
    "phenotype_data = phenotype_data[phenotype_data[subtype_column].isin(selected_subtypes)]\n",
    "after_filter = len(phenotype_data)\n",
    "removed_samples = before_filter - after_filter\n",
    "print(f\"ğŸ“Š Removed {removed_samples} samples ({removed_samples/before_filter*100:.1f}%)\")\n",
    "print(f\"ğŸ“Š Remaining samples: {after_filter}\")\n",
    "\n",
    "# Check for missing subtypes\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"\\nğŸ” Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    print(\"ğŸ”„ Removing samples with missing subtypes...\")\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"ğŸ“Š Removed {missing_subtypes} samples with missing subtypes\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"âœ… No missing subtypes found\")\n",
    "\n",
    "print(f\"ğŸ“Š Clean phenotype data shape: {phenotype_data_clean.shape}\")\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "print(\"\\nğŸ”„ Encoding subtypes as numeric labels...\")\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create and display encoding mapping\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"ğŸ“‹ Subtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"   {encoded}: {subtype}\")\n",
    "\n",
    "# Convert to pandas Series for easy handling\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nğŸ“Š Encoded subtype distribution:\")\n",
    "encoded_counts = subtype_encoded.value_counts().sort_index()\n",
    "for label, count in encoded_counts.items():\n",
    "    subtype_name = label_encoder.classes_[label]\n",
    "    print(f\"   Class {label}: {count} samples ({subtype_name})\")\n",
    "\n",
    "print(\"\\nâœ… Phenotype data processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d7ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Sample Alignment...\n",
      "==================================================\n",
      "ğŸ”„ Updating common samples: 205 â†’ 205\n",
      "ğŸ“Š Removed 0 samples (missing subtypes or not in selected subtypes)\n",
      "\n",
      "ğŸ”„ Aligning all datasets to valid samples...\n",
      "\n",
      "ğŸ“ Final aligned data shapes:\n",
      "   Expression: (60660, 205) (genes x samples)\n",
      "   Methylation: (396650, 205) (probes x samples)\n",
      "   Copy Number: (56756, 205) (regions x samples)\n",
      "   Phenotype: (205, 78) (samples x features)\n",
      "   Subtypes: 205 (samples)\n",
      "   Common samples: 205\n",
      "\n",
      "âœ… All datasets have consistent sample alignment!\n",
      "\n",
      "âœ… Final sample alignment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Sample Alignment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "print(f\"ğŸ”„ Updating common samples: {len(common_samples)} â†’ {len(valid_samples)}\")\n",
    "removed_samples = len(common_samples) - len(valid_samples)\n",
    "print(f\"ğŸ“Š Removed {removed_samples} samples (missing subtypes or not in selected subtypes)\")\n",
    "\n",
    "# Align all datasets to valid samples\n",
    "print(\"\\nğŸ”„ Aligning all datasets to valid samples...\")\n",
    "expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "methylation_scaled = methylation_scaled[valid_samples]\n",
    "copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "phenotype_data_clean = phenotype_data_clean.loc[valid_samples]\n",
    "common_samples = valid_samples\n",
    "\n",
    "# Final shape verification\n",
    "print(f\"\\nğŸ“ Final aligned data shapes:\")\n",
    "print(f\"   Expression: {expression_data_scaled.shape} (genes x samples)\")\n",
    "print(f\"   Methylation: {methylation_scaled.shape} (probes x samples)\")\n",
    "print(f\"   Copy Number: {copy_number_scaled.shape} (regions x samples)\")\n",
    "print(f\"   Phenotype: {phenotype_data_clean.shape} (samples x features)\")\n",
    "print(f\"   Subtypes: {len(subtype_encoded)} (samples)\")\n",
    "print(f\"   Common samples: {len(common_samples)}\")\n",
    "\n",
    "# Verify sample consistency\n",
    "sample_sets = [\n",
    "    set(expression_data_scaled.columns),\n",
    "    set(methylation_scaled.columns),\n",
    "    set(copy_number_scaled.columns),\n",
    "    set(subtype_encoded.index),\n",
    "    set(phenotype_data_clean.index)\n",
    "]\n",
    "\n",
    "all_consistent = all(s == sample_sets[0] for s in sample_sets)\n",
    "if all_consistent:\n",
    "    print(\"\\nâœ… All datasets have consistent sample alignment!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Warning: Sample alignment inconsistency detected!\")\n",
    "\n",
    "print(\"\\nâœ… Final sample alignment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca1524",
   "metadata": {},
   "source": [
    "## 11. Data Export\n",
    "Save processed datasets for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c06bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Exporting Processed Data...\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# Define output directory\n",
    "# output_dir = \"../Updated_model_nd_dataset/\"\n",
    "# # Save main processed files (features as rows, samples as columns)\n",
    "# expression_data_scaled.to_csv(f\"{output_dir}processed_expression_FXS_OG.csv\", mode='w')\n",
    "# methylation_scaled.to_csv(f\"{output_dir}processed_methylation_FXS_OG.csv\", mode='w')\n",
    "# copy_number_scaled.to_csv(f\"{output_dir}processed_cnv_FXS_OG.csv\", mode='w')\n",
    "# phenotype_data_clean.to_csv(f\"{output_dir}processed_phenotype_FXS_OG.csv\", mode='w')\n",
    "# subtype_encoded.to_csv(f\"{output_dir}processed_labels_3Omics_FXS_OG.csv\", header=True, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
