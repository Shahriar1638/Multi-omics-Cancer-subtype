{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e11d077",
   "metadata": {},
   "source": [
    "# Multi-Omics Data Preprocessing Pipeline\n",
    "## TCGA-SARC Dataset - 3 Omics Integration\n",
    "\n",
    "This notebook contains the complete preprocessing pipeline for multi-omics data integration:\n",
    "- **Expression Data**: Gene expression (TPM values)\n",
    "- **Methylation Data**: DNA methylation (Beta values)\n",
    "- **Copy Number Data**: Copy number variations (ASCAT3)\n",
    "- **Clinical Data**: Phenotype and subtype information\n",
    "\n",
    "**Output**: Clean, standardized datasets ready for machine learning and integration methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3450ef8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2844558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c4bc7",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load raw TCGA-SARC multi-omics datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17edada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading TCGA-SARC multi-omics datasets...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load multi-omics data\n",
    "expression_data = pd.read_csv('../TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('../TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('../TCGA-SARC.gene-level_ascat3.tsv', sep='\\t', index_col=0) # Copy number variations\n",
    "\n",
    "# Load clinical data with error handling\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Initial load failed ({e}), attempting with error handling...\")\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Raw data shapes:\")\n",
    "print(f\"üìä Expression data: {expression_data.shape} (genes x samples)\")\n",
    "print(f\"üß¨ Methylation data: {methylation_data.shape} (CpG sites x samples)\")\n",
    "print(f\"üìà Copy number data: {copy_number_data.shape} (genes x samples)\")\n",
    "print(f\"üè• Clinical data: {phenotype_data.shape} (samples x features)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc85cc0",
   "metadata": {},
   "source": [
    "## 3. Sample Matching & Quality Control\n",
    "Identify common samples across all omics platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample matching and quality assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check sample overlap between different omics data\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "\n",
    "print(\"Sample counts per modality:\")\n",
    "print(f\"üß¨ Expression samples: {len(samples_expression)}\")\n",
    "print(f\"üî¨ Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"üìä CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"üè• Clinical samples: {len(samples_clinical)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical))\n",
    "print(f\"\\nüéØ Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]\n",
    "\n",
    "print(f\"\\nüìè Filtered data shapes:\")\n",
    "print(f\"Expression: {expression_data.shape}\")\n",
    "print(f\"Methylation: {methylation_data.shape}\")\n",
    "print(f\"Copy Number: {copy_number_data.shape}\")\n",
    "print(f\"Clinical: {phenotype_data.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Sample matching completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5784a6",
   "metadata": {},
   "source": [
    "## 4. Missing Value Assessment\n",
    "Comprehensive analysis of missing values across all omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing value assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for null values in each omics modality\n",
    "def assess_missing_values(data, name):\n",
    "    total_values = data.size\n",
    "    missing_count = data.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / total_values) * 100\n",
    "    \n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    print(f\"   Total values: {total_values:,}\")\n",
    "    print(f\"   Missing values: {missing_count:,}\")\n",
    "    print(f\"   Missing percentage: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Contains missing values - preprocessing required\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No missing values found\")\n",
    "    \n",
    "    return missing_count, missing_percentage\n",
    "\n",
    "# Assess each omics modality\n",
    "expr_missing, expr_pct = assess_missing_values(expression_data, \"Expression Data\")\n",
    "meth_missing, meth_pct = assess_missing_values(methylation_data, \"Methylation Data\")\n",
    "cnv_missing, cnv_pct = assess_missing_values(copy_number_data, \"Copy Number Data\")\n",
    "pheno_missing, pheno_pct = assess_missing_values(phenotype_data, \"Phenotype Data\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüìã MISSING VALUE SUMMARY:\")\n",
    "print(f\"Expression: {expr_missing:,} ({expr_pct:.2f}%)\")\n",
    "print(f\"Methylation: {meth_missing:,} ({meth_pct:.2f}%)\")\n",
    "print(f\"Copy Number: {cnv_missing:,} ({cnv_pct:.2f}%)\")\n",
    "print(f\"Phenotype: {pheno_missing:,} ({pheno_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing value assessment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a87815",
   "metadata": {},
   "source": [
    "## 5. Expression Data Preprocessing\n",
    "Process gene expression data: imputation ‚Üí log transformation ‚Üí standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Expression Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä Original shape: {expression_data.shape}\")\n",
    "print(f\"üìä Value range: [{expression_data.min().min():.3f}, {expression_data.max().max():.3f}]\")\n",
    "\n",
    "# Step 1: Fill missing values gene-wise (mean across samples)\n",
    "if expression_data.isnull().sum().sum() > 0:\n",
    "    print(\"üîÑ Imputing missing values with gene-wise mean...\")\n",
    "    expression_data = expression_data.fillna(expression_data.mean(axis=1))\n",
    "    print(f\"‚úÖ Missing values after imputation: {expression_data.isnull().sum().sum()}\")\n",
    "\n",
    "# Step 2: Log2 transformation (add pseudocount for zero values)\n",
    "print(\"üîÑ Applying log2 transformation...\")\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "print(f\"üìä After log2: [{expression_data_log.min().min():.3f}, {expression_data_log.max().max():.3f}]\")\n",
    "\n",
    "# Step 3: Z-score standardization (samples as features)\n",
    "print(\"üîÑ Applying Z-score standardization...\")\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "print(f\"üìä Final shape: {expression_data_scaled.shape}\")\n",
    "print(f\"üìä Final range: [{expression_data_scaled.min().min():.3f}, {expression_data_scaled.max().max():.3f}]\")\n",
    "print(f\"üìä Mean: {expression_data_scaled.mean().mean():.6f}\")\n",
    "print(f\"üìä Std: {expression_data_scaled.std().mean():.6f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Expression data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb7eee",
   "metadata": {},
   "source": [
    "## 6. Methylation Data Preprocessing\n",
    "Process DNA methylation data: quality filtering ‚Üí imputation ‚Üí no scaling (preserve beta values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Methylation Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä Original shape: {methylation_data.shape}\")\n",
    "print(f\"üìä Value range: [{methylation_data.min().min():.3f}, {methylation_data.max().max():.3f}]\")\n",
    "print(f\"üìä Missing values: {methylation_data.isnull().sum().sum():,}\")\n",
    "\n",
    "# Step 1: Drop probes with >20% missing values (80% threshold)\n",
    "print(\"üîÑ Removing probes with >20% missing values...\")\n",
    "before_filter = methylation_data.shape[0]\n",
    "methylation_data = methylation_data.dropna(thresh=0.80 * methylation_data.shape[1], axis=0)\n",
    "after_filter = methylation_data.shape[0]\n",
    "removed_probes = before_filter - after_filter\n",
    "print(f\"üìä Removed {removed_probes:,} probes ({removed_probes/before_filter*100:.1f}%)\")\n",
    "print(f\"üìä Remaining probes: {after_filter:,}\")\n",
    "\n",
    "# Step 2: Impute remaining missing values probe-wise (mean across samples)\n",
    "print(\"üîÑ Imputing remaining missing values with probe-wise mean...\")\n",
    "methylation_data = methylation_data.fillna(methylation_data.mean(axis=1))\n",
    "print(f\"‚úÖ Missing values after imputation: {methylation_data.isnull().sum().sum()}\")\n",
    "\n",
    "# Step 3: Remove low-variance probes (threshold = 0.01)\n",
    "print(\"üîÑ Removing low-variance probes...\")\n",
    "before_variance = methylation_data.shape[0]\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_filtered = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_data.T).T,\n",
    "    index=methylation_data.index[selector.get_support()],\n",
    "    columns=methylation_data.columns\n",
    ")\n",
    "after_variance = methylation_filtered.shape[0]\n",
    "removed_low_var = before_variance - after_variance\n",
    "print(f\"üìä Removed {removed_low_var:,} low-variance probes ({removed_low_var/before_variance*100:.1f}%)\")\n",
    "\n",
    "# Step 4: Handle any NaNs introduced by VarianceThreshold\n",
    "if methylation_filtered.isnull().sum().sum() > 0:\n",
    "    print(f\"üîÑ Filling {methylation_filtered.isnull().sum().sum()} NaNs after variance filtering...\")\n",
    "    methylation_filtered = methylation_filtered.fillna(methylation_filtered.mean(axis=1))\n",
    "\n",
    "# Step 5: NO SCALING - Keep original beta values (0-1 range)\n",
    "print(\"üìã Preserving original beta values (no scaling applied)\")\n",
    "methylation_scaled = methylation_filtered.copy()\n",
    "\n",
    "print(f\"üìä Final shape: {methylation_scaled.shape}\")\n",
    "print(f\"üìä Final range: [{methylation_scaled.min().min():.3f}, {methylation_scaled.max().max():.3f}]\")\n",
    "print(f\"üìä Missing values: {methylation_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Methylation data preprocessing completed!\")\n",
    "print(\"üß¨ Beta values preserved for biological interpretability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaba25b",
   "metadata": {},
   "source": [
    "## 7. Copy Number Data Preprocessing\n",
    "Process copy number variations: filtering ‚Üí imputation ‚Üí biological constraints ‚Üí standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Copy Number Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä Original shape: {copy_number_data.shape}\")\n",
    "print(f\"üìä Value range: [{copy_number_data.min().min():.3f}, {copy_number_data.max().max():.3f}]\")\n",
    "print(f\"üìä Missing values: {copy_number_data.isnull().sum().sum():,}\")\n",
    "\n",
    "# Step 1: Drop genes with >20% missing values\n",
    "print(\"üîÑ Removing genes with >20% missing values...\")\n",
    "gene_missing_threshold = 0.2\n",
    "before_filter = copy_number_data.shape[0]\n",
    "copy_number_data_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "after_filter = copy_number_data_filtered.shape[0]\n",
    "removed_genes = before_filter - after_filter\n",
    "print(f\"üìä Removed {removed_genes:,} genes ({removed_genes/before_filter*100:.1f}%)\")\n",
    "print(f\"üìä Remaining genes: {after_filter:,}\")\n",
    "\n",
    "# Step 2: Impute remaining missing values gene-wise (mode preferred, fallback to mean)\n",
    "print(\"üîÑ Imputing missing values (mode ‚Üí mean fallback)...\")\n",
    "copy_number_data_imputed = copy_number_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.mode().iloc[0]) if not row.mode().empty else row.fillna(row.mean()),\n",
    "    axis=1\n",
    ")\n",
    "print(f\"‚úÖ Missing values after imputation: {copy_number_data_imputed.isnull().sum().sum()}\")\n",
    "\n",
    "# Step 3: Cap values to biologically plausible range (0-6 copies)\n",
    "print(\"üîÑ Applying biological constraints (0-6 copies)...\")\n",
    "print(f\"üìä Before clipping: [{copy_number_data_imputed.min().min():.3f}, {copy_number_data_imputed.max().max():.3f}]\")\n",
    "cnv_clipped = copy_number_data_imputed.clip(lower=0, upper=6)\n",
    "print(f\"üìä After clipping: [{cnv_clipped.min().min():.3f}, {cnv_clipped.max().max():.3f}]\")\n",
    "\n",
    "# Step 4: Log2 ratio relative to diploid (2 copies = normal)\n",
    "print(\"üîÑ Converting to log2 ratios (diploid = 0)...\")\n",
    "log_cnv = np.log2(cnv_clipped / 2)\n",
    "print(f\"üìä Log2 ratio range: [{log_cnv.min().min():.3f}, {log_cnv.max().max():.3f}]\")\n",
    "\n",
    "# Step 5: Keep only variable regions (std > 0.2)\n",
    "print(\"üîÑ Filtering for variable regions...\")\n",
    "before_var_filter = log_cnv.shape[0]\n",
    "copy_number_scaled = log_cnv.loc[log_cnv.std(axis=1) > 0.2]\n",
    "after_var_filter = copy_number_scaled.shape[0]\n",
    "removed_invariant = before_var_filter - after_var_filter\n",
    "print(f\"üìä Removed {removed_invariant:,} invariant regions ({removed_invariant/before_var_filter*100:.1f}%)\")\n",
    "\n",
    "print(f\"üìä Final shape: {copy_number_scaled.shape}\")\n",
    "print(f\"üìä Final range: [{copy_number_scaled.min().min():.3f}, {copy_number_scaled.max().max():.3f}]\")\n",
    "print(f\"üìä Missing values: {copy_number_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Copy number data preprocessing completed!\")\n",
    "print(\"üìà Log2 ratios ready for downstream analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41d4d7",
   "metadata": {},
   "source": [
    "## 8. Phenotype Data Processing\n",
    "Extract and encode cancer subtypes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Phenotype Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define subtype column and selected subtypes\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "selected_subtypes = [\n",
    "    'Leiomyosarcoma, NOS',\n",
    "    'Dedifferentiated liposarcoma',\n",
    "    'Undifferentiated sarcoma',\n",
    "    'Fibromyxosarcoma'\n",
    "]\n",
    "\n",
    "print(f\"üéØ Target column: '{subtype_column}'\")\n",
    "print(f\"üìä Original subtype distribution:\")\n",
    "subtype_counts = phenotype_data[subtype_column].value_counts()\n",
    "for subtype, count in subtype_counts.items():\n",
    "    marker = \"‚úÖ\" if subtype in selected_subtypes else \"‚ùå\"\n",
    "    print(f\"   {marker} {subtype}: {count}\")\n",
    "\n",
    "# Filter to selected subtypes only\n",
    "print(f\"\\nüîÑ Filtering to selected subtypes...\")\n",
    "before_filter = len(phenotype_data)\n",
    "phenotype_data = phenotype_data[phenotype_data[subtype_column].isin(selected_subtypes)]\n",
    "after_filter = len(phenotype_data)\n",
    "removed_samples = before_filter - after_filter\n",
    "print(f\"üìä Removed {removed_samples} samples ({removed_samples/before_filter*100:.1f}%)\")\n",
    "print(f\"üìä Remaining samples: {after_filter}\")\n",
    "\n",
    "# Check for missing subtypes\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"\\nüîç Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    print(\"üîÑ Removing samples with missing subtypes...\")\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"üìä Removed {missing_subtypes} samples with missing subtypes\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"‚úÖ No missing subtypes found\")\n",
    "\n",
    "print(f\"üìä Clean phenotype data shape: {phenotype_data_clean.shape}\")\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "print(\"\\nüîÑ Encoding subtypes as numeric labels...\")\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create and display encoding mapping\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"üìã Subtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"   {encoded}: {subtype}\")\n",
    "\n",
    "# Convert to pandas Series for easy handling\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nüìä Encoded subtype distribution:\")\n",
    "encoded_counts = subtype_encoded.value_counts().sort_index()\n",
    "for label, count in encoded_counts.items():\n",
    "    subtype_name = label_encoder.classes_[label]\n",
    "    print(f\"   Class {label}: {count} samples ({subtype_name})\")\n",
    "\n",
    "print(\"\\n‚úÖ Phenotype data processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84ae0e",
   "metadata": {},
   "source": [
    "## 9. Final Sample Alignment\n",
    "Ensure all datasets have consistent samples after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Sample Alignment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "print(f\"üîÑ Updating common samples: {len(common_samples)} ‚Üí {len(valid_samples)}\")\n",
    "removed_samples = len(common_samples) - len(valid_samples)\n",
    "print(f\"üìä Removed {removed_samples} samples (missing subtypes or not in selected subtypes)\")\n",
    "\n",
    "# Align all datasets to valid samples\n",
    "print(\"\\nüîÑ Aligning all datasets to valid samples...\")\n",
    "expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "methylation_scaled = methylation_scaled[valid_samples]\n",
    "copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "phenotype_data_clean = phenotype_data_clean.loc[valid_samples]\n",
    "common_samples = valid_samples\n",
    "\n",
    "# Final shape verification\n",
    "print(f\"\\nüìè Final aligned data shapes:\")\n",
    "print(f\"   Expression: {expression_data_scaled.shape} (genes x samples)\")\n",
    "print(f\"   Methylation: {methylation_scaled.shape} (probes x samples)\")\n",
    "print(f\"   Copy Number: {copy_number_scaled.shape} (regions x samples)\")\n",
    "print(f\"   Phenotype: {phenotype_data_clean.shape} (samples x features)\")\n",
    "print(f\"   Subtypes: {len(subtype_encoded)} (samples)\")\n",
    "print(f\"   Common samples: {len(common_samples)}\")\n",
    "\n",
    "# Verify sample consistency\n",
    "sample_sets = [\n",
    "    set(expression_data_scaled.columns),\n",
    "    set(methylation_scaled.columns),\n",
    "    set(copy_number_scaled.columns),\n",
    "    set(subtype_encoded.index),\n",
    "    set(phenotype_data_clean.index)\n",
    "]\n",
    "\n",
    "all_consistent = all(s == sample_sets[0] for s in sample_sets)\n",
    "if all_consistent:\n",
    "    print(\"\\n‚úÖ All datasets have consistent sample alignment!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Warning: Sample alignment inconsistency detected!\")\n",
    "\n",
    "print(\"\\n‚úÖ Final sample alignment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6053d0",
   "metadata": {},
   "source": [
    "## 10. Data Quality Verification\n",
    "Final quality checks before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Quality Verification...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def verify_data_quality(data, name, expected_range=None):\n",
    "    print(f\"\\nüîç {name}:\")\n",
    "    print(f\"   Shape: {data.shape}\")\n",
    "    print(f\"   Missing values: {data.isnull().sum().sum():,}\")\n",
    "    print(f\"   Data type: {data.dtypes.iloc[0] if hasattr(data, 'dtypes') else type(data.iloc[0] if hasattr(data, 'iloc') else data[0])}\")\n",
    "    \n",
    "    if hasattr(data, 'min') and hasattr(data, 'max'):\n",
    "        min_val = data.min().min() if hasattr(data.min(), 'min') else data.min()\n",
    "        max_val = data.max().max() if hasattr(data.max(), 'max') else data.max()\n",
    "        print(f\"   Value range: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "        \n",
    "        if expected_range:\n",
    "            if expected_range[0] <= min_val <= max_val <= expected_range[1]:\n",
    "                print(f\"   ‚úÖ Values within expected range {expected_range}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Values outside expected range {expected_range}\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    if hasattr(data, 'values'):\n",
    "        inf_count = np.isinf(data.values).sum()\n",
    "        if inf_count > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Contains {inf_count} infinite values\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ No infinite values\")\n",
    "\n",
    "# Verify each dataset\n",
    "verify_data_quality(expression_data_scaled, \"Expression Data (Standardized)\")\n",
    "verify_data_quality(methylation_scaled, \"Methylation Data (Beta Values)\", expected_range=(0, 1))\n",
    "verify_data_quality(copy_number_scaled, \"Copy Number Data (Log2 Ratios)\")\n",
    "verify_data_quality(subtype_encoded, \"Subtype Labels\", expected_range=(0, len(label_encoder.classes_)-1))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä PREPROCESSING SUMMARY:\")\n",
    "print(f\"   Total samples: {len(common_samples)}\")\n",
    "print(f\"   Expression features: {expression_data_scaled.shape[0]:,}\")\n",
    "print(f\"   Methylation features: {methylation_scaled.shape[0]:,}\")\n",
    "print(f\"   Copy number features: {copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Total features: {expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Number of classes: {len(np.unique(subtype_encoded))}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data quality verification completed!\")\n",
    "print(\"üéâ All datasets are ready for machine learning and integration methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca1524",
   "metadata": {},
   "source": [
    "## 11. Data Export\n",
    "Save processed datasets for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c06bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting Processed Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"../Updated_model_nd_dataset/\"\n",
    "\n",
    "# Save processed datasets\n",
    "print(\"üîÑ Saving processed datasets...\")\n",
    "\n",
    "# Save main processed files (features as rows, samples as columns)\n",
    "expression_data_scaled.to_csv(f\"{output_dir}processed_expression_FXS_OG.csv\")\n",
    "methylation_scaled.to_csv(f\"{output_dir}processed_methylation_FXS_OG.csv\")\n",
    "copy_number_scaled.to_csv(f\"{output_dir}processed_cnv_FXS_OG.csv\")\n",
    "phenotype_data_clean.to_csv(f\"{output_dir}processed_phenotype_FXS_OG.csv\")\n",
    "subtype_encoded.to_csv(f\"{output_dir}processed_labels_3Omics_FXS_OG.csv\", header=True)\n",
    "\n",
    "print(\"‚úÖ Main datasets saved (features as rows)\")\n",
    "\n",
    "# Save transposed versions for ML models (samples as rows, features as columns)\n",
    "print(\"üîÑ Creating and saving transposed versions for ML...\")\n",
    "\n",
    "expression_data_scaled.T.to_csv(f\"{output_dir}processed_expression_SXF_MAS.csv\")\n",
    "methylation_scaled.T.to_csv(f\"{output_dir}processed_methylation_SXF_MAS.csv\")\n",
    "copy_number_scaled.T.to_csv(f\"{output_dir}processed_cnv_SXF_MAS.csv\")\n",
    "\n",
    "print(\"‚úÖ Transposed datasets saved (samples as rows)\")\n",
    "\n",
    "# Save metadata and mappings\n",
    "print(\"üîÑ Saving metadata...\")\n",
    "\n",
    "# Save subtype mapping\n",
    "mapping_df = pd.DataFrame([\n",
    "    {'encoded_label': k, 'subtype_name': v} \n",
    "    for v, k in subtype_mapping.items()\n",
    "])\n",
    "mapping_df.to_csv(f\"{output_dir}subtype_mapping.csv\", index=False)\n",
    "\n",
    "# Save processing summary\n",
    "summary_info = {\n",
    "    'total_samples': len(common_samples),\n",
    "    'expression_features': expression_data_scaled.shape[0],\n",
    "    'methylation_features': methylation_scaled.shape[0],\n",
    "    'copy_number_features': copy_number_scaled.shape[0],\n",
    "    'total_features': expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0],\n",
    "    'num_classes': len(np.unique(subtype_encoded)),\n",
    "    'class_names': list(label_encoder.classes_)\n",
    "}\n",
    "\n",
    "with open(f\"{output_dir}preprocessing_summary.txt\", 'w') as f:\n",
    "    f.write(\"TCGA-SARC Multi-Omics Preprocessing Summary\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    for key, value in summary_info.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"‚úÖ Metadata saved\")\n",
    "\n",
    "# Display saved files\n",
    "print(f\"\\nüìÅ Saved files in '{output_dir}':\")\n",
    "saved_files = [\n",
    "    \"processed_expression_FXS_MAS.csv (genes x samples)\",\n",
    "    \"processed_methylation_FXS_MAS.csv (probes x samples)\", \n",
    "    \"processed_cnv_FXS_MAS.csv (regions x samples)\",\n",
    "    \"processed_expression_SXF_MAS.csv (samples x genes)\",\n",
    "    \"processed_methylation_SXF_MAS.csv (samples x probes)\",\n",
    "    \"processed_cnv_SXF_MAS.csv (samples x regions)\",\n",
    "    \"processed_phenotype_FXS_MAS.csv\",\n",
    "    \"processed_labels_3Omics_MAS.csv\",\n",
    "    \"subtype_mapping.csv\",\n",
    "    \"preprocessing_summary.txt\"\n",
    "]\n",
    "\n",
    "for file in saved_files:\n",
    "    print(f\"   üìÑ {file}\")\n",
    "\n",
    "print(\"\\nüéâ Data export completed successfully!\")\n",
    "print(\"üöÄ Ready for multi-omics integration and machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4feb1",
   "metadata": {},
   "source": [
    "## 12. Preprocessing Pipeline Summary\n",
    "\n",
    "### üìä **Final Dataset Overview:**\n",
    "- **Expression Data**: Log2-transformed TPM values, Z-score standardized\n",
    "- **Methylation Data**: Beta values (0-1), no scaling to preserve biological meaning  \n",
    "- **Copy Number Data**: Log2 ratios relative to diploid, variable regions only\n",
    "- **Subtype Labels**: 4 sarcoma subtypes encoded as 0-3\n",
    "\n",
    "### üîß **Processing Strategy:**\n",
    "1. **Sample Alignment**: Matched samples across all omics platforms\n",
    "2. **Quality Filtering**: Removed high-missing features and low-variance regions\n",
    "3. **Biologically-Informed Imputation**: Appropriate strategies per omics type\n",
    "4. **Scaling Strategy**: Standardized where beneficial, preserved ranges where meaningful\n",
    "5. **Feature Selection**: Focused on variable and informative features\n",
    "\n",
    "### üéØ **Ready for:**\n",
    "- Multi-omics integration methods (MOFA, iCluster, etc.)\n",
    "- Machine learning classification\n",
    "- Deep learning models\n",
    "- Graph neural networks\n",
    "- Survival analysis\n",
    "\n",
    "### üìà **Quality Assurance:**\n",
    "- ‚úÖ No missing values in final datasets\n",
    "- ‚úÖ Biologically plausible value ranges\n",
    "- ‚úÖ Consistent sample alignment\n",
    "- ‚úÖ Balanced class representation\n",
    "- ‚úÖ Reproducible preprocessing pipeline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
