{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2844558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0+cu129\n",
      "Device available: CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c4bc7",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load raw TCGA-SARC multi-omics datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b17edada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TCGA-SARC multi-omics datasets...\n",
      "==================================================\n",
      "Raw data shapes:\n",
      "üìä Expression data: (60660, 265) (genes x samples)\n",
      "üß¨ Methylation data: (486427, 269) (CpG sites x samples)\n",
      "üìà Copy number data: (60623, 248) (genes x samples)\n",
      "üè• Clinical data: (272, 78) (samples x features)\n",
      "\n",
      "‚úÖ Data loading completed!\n",
      "Raw data shapes:\n",
      "üìä Expression data: (60660, 265) (genes x samples)\n",
      "üß¨ Methylation data: (486427, 269) (CpG sites x samples)\n",
      "üìà Copy number data: (60623, 248) (genes x samples)\n",
      "üè• Clinical data: (272, 78) (samples x features)\n",
      "\n",
      "‚úÖ Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading TCGA-SARC multi-omics datasets...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load multi-omics data\n",
    "expression_data = pd.read_csv('../TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('../TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('../TCGA-SARC.gene-level_absolute.tsv', sep='\\t', index_col=0) # Copy number variations (absolute)\n",
    "\n",
    "# Load clinical data with error handling\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Initial load failed ({e}), attempting with error handling...\")\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Raw data shapes:\")\n",
    "print(f\"üìä Expression data: {expression_data.shape} (genes x samples)\")\n",
    "print(f\"üß¨ Methylation data: {methylation_data.shape} (CpG sites x samples)\")\n",
    "print(f\"üìà Copy number data: {copy_number_data.shape} (genes x samples)\")\n",
    "print(f\"üè• Clinical data: {phenotype_data.shape} (samples x features)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc85cc0",
   "metadata": {},
   "source": [
    "## 3. Sample Matching & Quality Control\n",
    "Identify common samples across all omics platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1acea1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample matching and quality assessment...\n",
      "==================================================\n",
      "Sample counts per modality:\n",
      "üß¨ Expression samples: 265\n",
      "üî¨ Methylation samples: 269\n",
      "üìä CNV samples: 248\n",
      "üè• Clinical samples: 272\n",
      "\n",
      "üéØ Common samples across all omics: 246\n",
      "\n",
      "üìè Filtered data shapes:\n",
      "Expression: (60660, 246)\n",
      "Methylation: (486427, 246)\n",
      "Copy Number: (60623, 246)\n",
      "Clinical: (246, 78)\n",
      "\n",
      "‚úÖ Sample matching completed!\n",
      "\n",
      "üìè Filtered data shapes:\n",
      "Expression: (60660, 246)\n",
      "Methylation: (486427, 246)\n",
      "Copy Number: (60623, 246)\n",
      "Clinical: (246, 78)\n",
      "\n",
      "‚úÖ Sample matching completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample matching and quality assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check sample overlap between different omics data\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "\n",
    "print(\"Sample counts per modality:\")\n",
    "print(f\"üß¨ Expression samples: {len(samples_expression)}\")\n",
    "print(f\"üî¨ Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"üìä CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"üè• Clinical samples: {len(samples_clinical)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical))\n",
    "print(f\"\\nüéØ Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]\n",
    "\n",
    "print(f\"\\nüìè Filtered data shapes:\")\n",
    "print(f\"Expression: {expression_data.shape}\")\n",
    "print(f\"Methylation: {methylation_data.shape}\")\n",
    "print(f\"Copy Number: {copy_number_data.shape}\")\n",
    "print(f\"Clinical: {phenotype_data.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Sample matching completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5784a6",
   "metadata": {},
   "source": [
    "## 4. Missing Value Assessment\n",
    "Comprehensive analysis of missing values across all omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fce29fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value assessment...\n",
      "==================================================\n",
      "\n",
      "üìä Expression Data:\n",
      "   Total values: 14,922,360\n",
      "   Missing values: 0\n",
      "   Missing percentage: 0.00%\n",
      "   ‚úÖ No missing values found\n",
      "\n",
      "üìä Methylation Data:\n",
      "   Total values: 119,661,042\n",
      "   Missing values: 19,622,910\n",
      "   Missing percentage: 16.40%\n",
      "   ‚ö†Ô∏è  Contains missing values - preprocessing required\n",
      "\n",
      "üìä Copy Number Data:\n",
      "   Total values: 14,913,258\n",
      "   Missing values: 994,360\n",
      "   Missing percentage: 6.67%\n",
      "   ‚ö†Ô∏è  Contains missing values - preprocessing required\n",
      "\n",
      "üìä Phenotype Data:\n",
      "   Total values: 19,188\n",
      "   Missing values: 3,960\n",
      "   Missing percentage: 20.64%\n",
      "   ‚ö†Ô∏è  Contains missing values - preprocessing required\n",
      "\n",
      "üìã MISSING VALUE SUMMARY:\n",
      "Expression: 0 (0.00%)\n",
      "Methylation: 19,622,910 (16.40%)\n",
      "Copy Number: 994,360 (6.67%)\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Phenotype: 3,960 (20.64%)\n",
      "\n",
      "‚úÖ Missing value assessment completed!\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Phenotype: 3,960 (20.64%)\n",
      "\n",
      "‚úÖ Missing value assessment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for null values in each omics modality\n",
    "def assess_missing_values(data, name):\n",
    "    total_values = data.size\n",
    "    missing_count = data.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / total_values) * 100\n",
    "    \n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    print(f\"   Total values: {total_values:,}\")\n",
    "    print(f\"   Missing values: {missing_count:,}\")\n",
    "    print(f\"   Missing percentage: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Contains missing values - preprocessing required\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No missing values found\")\n",
    "    \n",
    "    return missing_count, missing_percentage\n",
    "\n",
    "# Assess each omics modality\n",
    "expr_missing, expr_pct = assess_missing_values(expression_data, \"Expression Data\")\n",
    "meth_missing, meth_pct = assess_missing_values(methylation_data, \"Methylation Data\")\n",
    "cnv_missing, cnv_pct = assess_missing_values(copy_number_data, \"Copy Number Data\")\n",
    "pheno_missing, pheno_pct = assess_missing_values(phenotype_data, \"Phenotype Data\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüìã MISSING VALUE SUMMARY:\")\n",
    "print(f\"Expression: {expr_missing:,} ({expr_pct:.2f}%)\")\n",
    "print(f\"Methylation: {meth_missing:,} ({meth_pct:.2f}%)\")\n",
    "print(f\"Copy Number: {cnv_missing:,} ({cnv_pct:.2f}%)\")\n",
    "max_value = copy_number_data.max().max()\n",
    "min_value = copy_number_data.min().min()\n",
    "\n",
    "print(f\"Maximum CNV value: {max_value}\")\n",
    "print(f\"Minimum CNV value: {min_value}\")\n",
    "print()\n",
    "print(f\"Phenotype: {pheno_missing:,} ({pheno_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing value assessment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4e49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Log2 transform\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "# Methylation data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Droping probes with more than 20% missing values \n",
    "methylation_data = methylation_data.dropna(thresh=0.8 * methylation_data.shape[1], axis=0)\n",
    "\n",
    "# fill na with probe wise median\n",
    "methylation_data = methylation_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "\n",
    "# Remove low-variance methylation probes\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_filtered = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_data.T).T,\n",
    "    index=methylation_data.index[selector.get_support()],\n",
    "    columns=methylation_data.columns\n",
    ")\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_meth = StandardScaler()\n",
    "methylation_scaled = pd.DataFrame(\n",
    "    scaler_meth.fit_transform(methylation_filtered.T).T,\n",
    "    index=methylation_filtered.index,\n",
    "    columns=methylation_filtered.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Copy number data preprocessing -------------------------------------------------->\n",
    "\n",
    "\n",
    "# Drop genes with >20% missing values\n",
    "gene_missing_threshold = 0.2\n",
    "copy_number_data_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "\n",
    "# filling null values with gene-wise median\n",
    "copy_number_imputed = copy_number_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_cnv = StandardScaler()\n",
    "copy_number_scaled = pd.DataFrame(\n",
    "    scaler_cnv.fit_transform(copy_number_imputed.T).T,\n",
    "    index=copy_number_imputed.index,\n",
    "    columns=copy_number_imputed.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c10026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Processing Methylation Data...\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# print(f\"üìä Original shape: {methylation_data.shape}\")\n",
    "# print(f\"üìä Value range: [{methylation_data.min().min():.3f}, {methylation_data.max().max():.3f}]\")\n",
    "# print(f\"üìä Missing values: {methylation_data.isnull().sum().sum():,}\")\n",
    "\n",
    "# # Step 1: Drop probes with >20% missing values (80% threshold)\n",
    "# print(\"üîÑ Removing probes with >20% missing values...\")\n",
    "# before_filter = methylation_data.shape[0]\n",
    "# methylation_data = methylation_data.dropna(thresh=0.80 * methylation_data.shape[1], axis=0)\n",
    "# after_filter = methylation_data.shape[0]\n",
    "# removed_probes = before_filter - after_filter\n",
    "# print(f\"üìä Removed {removed_probes:,} probes ({removed_probes/before_filter*100:.1f}%)\")\n",
    "# print(f\"üìä Remaining probes: {after_filter:,}\")\n",
    "\n",
    "# # Step 2: Impute remaining missing values probe-wise (mean across samples)\n",
    "# print(\"üîÑ Imputing remaining missing values with probe-wise mean...\")\n",
    "# methylation_data = methylation_data.fillna(methylation_data.mean(axis=1))\n",
    "# print(f\"‚úÖ Missing values after imputation: {methylation_data.isnull().sum().sum()}\")\n",
    "\n",
    "# # Step 3: Remove low-variance probes (threshold = 0.01)\n",
    "# print(\"üîÑ Removing low-variance probes...\")\n",
    "# before_variance = methylation_data.shape[0]\n",
    "# selector = VarianceThreshold(threshold=0.01)\n",
    "# methylation_filtered = pd.DataFrame(\n",
    "#     selector.fit_transform(methylation_data.T).T,\n",
    "#     index=methylation_data.index[selector.get_support()],\n",
    "#     columns=methylation_data.columns\n",
    "# )\n",
    "# after_variance = methylation_filtered.shape[0]\n",
    "# removed_low_var = before_variance - after_variance\n",
    "# print(f\"üìä Removed {removed_low_var:,} low-variance probes ({removed_low_var/before_variance*100:.1f}%)\")\n",
    "\n",
    "# # Step 4: Handle any NaNs introduced by VarianceThreshold\n",
    "# if methylation_filtered.isnull().sum().sum() > 0:\n",
    "#     print(f\"üîÑ Filling {methylation_filtered.isnull().sum().sum()} NaNs after variance filtering...\")\n",
    "#     methylation_filtered = methylation_filtered.fillna(methylation_filtered.mean(axis=1))\n",
    "\n",
    "# # Step 5: NO SCALING - Keep original beta values (0-1 range)\n",
    "# print(\"üìã Preserving original beta values (no scaling applied)\")\n",
    "# methylation_scaled = methylation_filtered.copy()\n",
    "\n",
    "# print(f\"üìä Final shape: {methylation_scaled.shape}\")\n",
    "# print(f\"üìä Final range: [{methylation_scaled.min().min():.3f}, {methylation_scaled.max().max():.3f}]\")\n",
    "# print(f\"üìä Missing values: {methylation_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "# print(\"\\n‚úÖ Methylation data preprocessing completed!\")\n",
    "# print(\"üß¨ Beta values preserved for biological interpretability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c52b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Phenotype Data...\n",
      "==================================================\n",
      "üéØ Target column: 'primary_diagnosis.diagnoses'\n",
      "üìä Original subtype distribution:\n",
      "   ‚úÖ Leiomyosarcoma, NOS: 96\n",
      "   ‚úÖ Dedifferentiated liposarcoma: 53\n",
      "   ‚úÖ Undifferentiated sarcoma: 34\n",
      "   ‚úÖ Fibromyxosarcoma: 22\n",
      "   ‚ùå Malignant fibrous histiocytoma: 11\n",
      "   ‚ùå Malignant peripheral nerve sheath tumor: 10\n",
      "   ‚ùå Synovial sarcoma, spindle cell: 6\n",
      "   ‚ùå Giant cell sarcoma: 3\n",
      "   ‚ùå Myxoid leiomyosarcoma: 2\n",
      "   ‚ùå Pleomorphic liposarcoma: 2\n",
      "   ‚ùå Synovial sarcoma, NOS: 2\n",
      "   ‚ùå Synovial sarcoma, biphasic: 2\n",
      "   ‚ùå Aggressive fibromatosis: 1\n",
      "   ‚ùå Liposarcoma, well differentiated: 1\n",
      "   ‚ùå Abdominal fibromatosis: 1\n",
      "\n",
      "üîÑ Filtering to selected subtypes...\n",
      "üìä Removed 41 samples (16.7%)\n",
      "üìä Remaining samples: 205\n",
      "\n",
      "üîç Missing values in subtype column: 0\n",
      "‚úÖ No missing subtypes found\n",
      "üìä Clean phenotype data shape: (205, 78)\n",
      "\n",
      "üîÑ Encoding subtypes as numeric labels...\n",
      "üìã Subtype encoding mapping:\n",
      "   0: Dedifferentiated liposarcoma\n",
      "   1: Fibromyxosarcoma\n",
      "   2: Leiomyosarcoma, NOS\n",
      "   3: Undifferentiated sarcoma\n",
      "\n",
      "üìä Encoded subtype distribution:\n",
      "   Class 0: 53 samples (Dedifferentiated liposarcoma)\n",
      "   Class 1: 22 samples (Fibromyxosarcoma)\n",
      "   Class 2: 96 samples (Leiomyosarcoma, NOS)\n",
      "   Class 3: 34 samples (Undifferentiated sarcoma)\n",
      "\n",
      "‚úÖ Phenotype data processing completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Phenotype Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define subtype column and selected subtypes\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "selected_subtypes = [\n",
    "    'Leiomyosarcoma, NOS',\n",
    "    'Dedifferentiated liposarcoma',\n",
    "    'Undifferentiated sarcoma',\n",
    "    'Fibromyxosarcoma'\n",
    "]\n",
    "\n",
    "print(f\"üéØ Target column: '{subtype_column}'\")\n",
    "print(f\"üìä Original subtype distribution:\")\n",
    "subtype_counts = phenotype_data[subtype_column].value_counts()\n",
    "for subtype, count in subtype_counts.items():\n",
    "    marker = \"‚úÖ\" if subtype in selected_subtypes else \"‚ùå\"\n",
    "    print(f\"   {marker} {subtype}: {count}\")\n",
    "\n",
    "# Filter to selected subtypes only\n",
    "print(f\"\\nüîÑ Filtering to selected subtypes...\")\n",
    "before_filter = len(phenotype_data)\n",
    "phenotype_data = phenotype_data[phenotype_data[subtype_column].isin(selected_subtypes)]\n",
    "after_filter = len(phenotype_data)\n",
    "removed_samples = before_filter - after_filter\n",
    "print(f\"üìä Removed {removed_samples} samples ({removed_samples/before_filter*100:.1f}%)\")\n",
    "print(f\"üìä Remaining samples: {after_filter}\")\n",
    "\n",
    "# Check for missing subtypes\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"\\nüîç Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    print(\"üîÑ Removing samples with missing subtypes...\")\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"üìä Removed {missing_subtypes} samples with missing subtypes\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"‚úÖ No missing subtypes found\")\n",
    "\n",
    "print(f\"üìä Clean phenotype data shape: {phenotype_data_clean.shape}\")\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "print(\"\\nüîÑ Encoding subtypes as numeric labels...\")\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create and display encoding mapping\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"üìã Subtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"   {encoded}: {subtype}\")\n",
    "\n",
    "# Convert to pandas Series for easy handling\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nüìä Encoded subtype distribution:\")\n",
    "encoded_counts = subtype_encoded.value_counts().sort_index()\n",
    "for label, count in encoded_counts.items():\n",
    "    subtype_name = label_encoder.classes_[label]\n",
    "    print(f\"   Class {label}: {count} samples ({subtype_name})\")\n",
    "\n",
    "print(\"\\n‚úÖ Phenotype data processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d7ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Sample Alignment...\n",
      "==================================================\n",
      "üîÑ Updating common samples: 246 ‚Üí 205\n",
      "üìä Removed 41 samples (missing subtypes or not in selected subtypes)\n",
      "\n",
      "üîÑ Aligning all datasets to valid samples...\n",
      "\n",
      "üìè Final aligned data shapes:\n",
      "   Expression: (60660, 205) (genes x samples)\n",
      "   Methylation: (220147, 205) (probes x samples)\n",
      "   Copy Number: (56756, 205) (regions x samples)\n",
      "   Phenotype: (205, 78) (samples x features)\n",
      "   Subtypes: 205 (samples)\n",
      "   Common samples: 205\n",
      "\n",
      "‚úÖ All datasets have consistent sample alignment!\n",
      "\n",
      "‚úÖ Final sample alignment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Sample Alignment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "print(f\"üîÑ Updating common samples: {len(common_samples)} ‚Üí {len(valid_samples)}\")\n",
    "removed_samples = len(common_samples) - len(valid_samples)\n",
    "print(f\"üìä Removed {removed_samples} samples (missing subtypes or not in selected subtypes)\")\n",
    "\n",
    "# Align all datasets to valid samples\n",
    "print(\"\\nüîÑ Aligning all datasets to valid samples...\")\n",
    "expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "methylation_scaled = methylation_scaled[valid_samples]\n",
    "copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "phenotype_data_clean = phenotype_data_clean.loc[valid_samples]\n",
    "common_samples = valid_samples\n",
    "\n",
    "# Final shape verification\n",
    "print(f\"\\nüìè Final aligned data shapes:\")\n",
    "print(f\"   Expression: {expression_data_scaled.shape} (genes x samples)\")\n",
    "print(f\"   Methylation: {methylation_scaled.shape} (probes x samples)\")\n",
    "print(f\"   Copy Number: {copy_number_scaled.shape} (regions x samples)\")\n",
    "print(f\"   Phenotype: {phenotype_data_clean.shape} (samples x features)\")\n",
    "print(f\"   Subtypes: {len(subtype_encoded)} (samples)\")\n",
    "print(f\"   Common samples: {len(common_samples)}\")\n",
    "\n",
    "# Verify sample consistency\n",
    "sample_sets = [\n",
    "    set(expression_data_scaled.columns),\n",
    "    set(methylation_scaled.columns),\n",
    "    set(copy_number_scaled.columns),\n",
    "    set(subtype_encoded.index),\n",
    "    set(phenotype_data_clean.index)\n",
    "]\n",
    "\n",
    "all_consistent = all(s == sample_sets[0] for s in sample_sets)\n",
    "if all_consistent:\n",
    "    print(\"\\n‚úÖ All datasets have consistent sample alignment!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Warning: Sample alignment inconsistency detected!\")\n",
    "\n",
    "print(\"\\n‚úÖ Final sample alignment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6053d0",
   "metadata": {},
   "source": [
    "## 10. Data Quality Verification\n",
    "Final quality checks before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb03bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Verification...\n",
      "==================================================\n",
      "\n",
      "üîç Expression Data (Standardized):\n",
      "   Shape: (60660, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-10.986, 15.652]\n",
      "   ‚úÖ No infinite values\n",
      "\n",
      "üîç Methylation Data (Beta Values):\n",
      "   Shape: (220147, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-9.054, 9.341]\n",
      "   ‚ö†Ô∏è  Values outside expected range (0, 1)\n",
      "   ‚úÖ No infinite values\n",
      "\n",
      "üîç Copy Number Data (Log2 Ratios):\n",
      "   Shape: (56756, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-2.967, 6.638]\n",
      "   ‚úÖ No infinite values\n",
      "\n",
      "üìä PREPROCESSING SUMMARY:\n",
      "   Total samples: 205\n",
      "   Expression features: 60,660\n",
      "   Methylation features: 220,147\n",
      "   Copy number features: 56,756\n",
      "   Total features: 337,563\n",
      "   Number of classes: 4\n",
      "\n",
      "‚úÖ Data quality verification completed!\n",
      "üéâ All datasets are ready for machine learning and integration methods!\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Quality Verification...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def verify_data_quality(data, name, expected_range=None):\n",
    "    print(f\"\\nüîç {name}:\")\n",
    "    print(f\"   Shape: {data.shape}\")\n",
    "    print(f\"   Missing values: {data.isnull().sum().sum():,}\")\n",
    "    print(f\"   Data type: {data.dtypes.iloc[0] if hasattr(data, 'dtypes') else type(data.iloc[0] if hasattr(data, 'iloc') else data[0])}\")\n",
    "    \n",
    "    if hasattr(data, 'min') and hasattr(data, 'max'):\n",
    "        min_val = data.min().min() if hasattr(data.min(), 'min') else data.min()\n",
    "        max_val = data.max().max() if hasattr(data.max(), 'max') else data.max()\n",
    "        print(f\"   Value range: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "        \n",
    "        if expected_range:\n",
    "            if expected_range[0] <= min_val <= max_val <= expected_range[1]:\n",
    "                print(f\"   ‚úÖ Values within expected range {expected_range}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Values outside expected range {expected_range}\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    if hasattr(data, 'values'):\n",
    "        inf_count = np.isinf(data.values).sum()\n",
    "        if inf_count > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Contains {inf_count} infinite values\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ No infinite values\")\n",
    "\n",
    "# Verify each dataset\n",
    "verify_data_quality(expression_data_scaled, \"Expression Data (Standardized)\")\n",
    "verify_data_quality(methylation_scaled, \"Methylation Data (Beta Values)\", expected_range=(0, 1))\n",
    "verify_data_quality(copy_number_scaled, \"Copy Number Data (Log2 Ratios)\")\n",
    "# verify_data_quality(subtype_encoded, \"Subtype Labels\", expected_range=(0, len(label_encoder.classes_)-1))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä PREPROCESSING SUMMARY:\")\n",
    "print(f\"   Total samples: {len(common_samples)}\")\n",
    "print(f\"   Expression features: {expression_data_scaled.shape[0]:,}\")\n",
    "print(f\"   Methylation features: {methylation_scaled.shape[0]:,}\")\n",
    "print(f\"   Copy number features: {copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Total features: {expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Number of classes: {len(np.unique(subtype_encoded))}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data quality verification completed!\")\n",
    "print(\"üéâ All datasets are ready for machine learning and integration methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca1524",
   "metadata": {},
   "source": [
    "## 11. Data Export\n",
    "Save processed datasets for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c06bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Processed Data...\n",
      "==================================================\n",
      "üîÑ Saving processed datasets...\n",
      "‚úÖ Main datasets saved (features as rows)\n",
      "üîÑ Creating and saving transposed versions for ML...\n",
      "‚úÖ Transposed datasets saved (samples as rows)\n",
      "üîÑ Saving metadata...\n",
      "‚úÖ Metadata saved\n",
      "\n",
      "üìÅ Saved files in '../Updated_model_nd_dataset/':\n",
      "   üìÑ processed_expression_FXS_OG.csv (genes x samples)\n",
      "   üìÑ processed_methylation_FXS_OG.csv (probes x samples)\n",
      "   üìÑ processed_cnv_FXS_OG.csv (regions x samples)\n",
      "   üìÑ processed_expression_SXF_OG.csv (samples x genes)\n",
      "   üìÑ processed_methylation_SXF_OG.csv (samples x probes)\n",
      "   üìÑ processed_cnv_SXF_OG.csv (samples x regions)\n",
      "   üìÑ processed_phenotype_FXS_OG.csv\n",
      "   üìÑ processed_labels_3Omics_OG.csv\n",
      "   üìÑ subtype_mapping.csv\n",
      "   üìÑ preprocessing_summary.txt\n",
      "\n",
      "üéâ Data export completed successfully!\n",
      "üöÄ Ready for multi-omics integration and machine learning!\n"
     ]
    }
   ],
   "source": [
    "# print(\"Exporting Processed Data...\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# # Define output directory\n",
    "# output_dir = \"../Updated_model_nd_dataset/\"\n",
    "\n",
    "# # Save processed datasets\n",
    "# print(\"üîÑ Saving processed datasets...\")\n",
    "\n",
    "# # Save main processed files (features as rows, samples as columns)\n",
    "# expression_data_scaled.to_csv(f\"{output_dir}processed_expression_FXS_OG.csv\")\n",
    "# methylation_scaled.to_csv(f\"{output_dir}processed_methylation_FXS_OG.csv\")\n",
    "# copy_number_scaled.to_csv(f\"{output_dir}processed_cnv_FXS_OG.csv\")\n",
    "# phenotype_data_clean.to_csv(f\"{output_dir}processed_phenotype_FXS_OG.csv\")\n",
    "# subtype_encoded.to_csv(f\"{output_dir}processed_labels_3Omics_FXS_OG.csv\", header=True)\n",
    "\n",
    "# print(\"‚úÖ Main datasets saved (features as rows)\")\n",
    "\n",
    "# # Save transposed versions for ML models (samples as rows, features as columns)\n",
    "# print(\"üîÑ Creating and saving transposed versions for ML...\")\n",
    "\n",
    "# expression_data_scaled.T.to_csv(f\"{output_dir}processed_expression_SXF_OG.csv\")\n",
    "# methylation_scaled.T.to_csv(f\"{output_dir}processed_methylation_SXF_OG.csv\")\n",
    "# copy_number_scaled.T.to_csv(f\"{output_dir}processed_cnv_SXF_OG.csv\")\n",
    "\n",
    "# print(\"‚úÖ Transposed datasets saved (samples as rows)\")\n",
    "\n",
    "# # Save metadata and mappings\n",
    "# print(\"üîÑ Saving metadata...\")\n",
    "\n",
    "# # Save subtype mapping\n",
    "# mapping_df = pd.DataFrame([\n",
    "#     {'encoded_label': k, 'subtype_name': v} \n",
    "#     for v, k in subtype_mapping.items()\n",
    "# ])\n",
    "# mapping_df.to_csv(f\"{output_dir}subtype_mapping.csv\", index=False)\n",
    "\n",
    "# # Save processing summary\n",
    "# summary_info = {\n",
    "#     'total_samples': len(common_samples),\n",
    "#     'expression_features': expression_data_scaled.shape[0],\n",
    "#     'methylation_features': methylation_scaled.shape[0],\n",
    "#     'copy_number_features': copy_number_scaled.shape[0],\n",
    "#     'total_features': expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0],\n",
    "#     'num_classes': len(np.unique(subtype_encoded)),\n",
    "#     'class_names': list(label_encoder.classes_)\n",
    "# }\n",
    "\n",
    "# with open(f\"{output_dir}preprocessing_summary.txt\", 'w') as f:\n",
    "#     f.write(\"TCGA-SARC Multi-Omics Preprocessing Summary\\n\")\n",
    "#     f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "#     for key, value in summary_info.items():\n",
    "#         f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "# print(\"‚úÖ Metadata saved\")\n",
    "\n",
    "# # Display saved files\n",
    "# print(f\"\\nüìÅ Saved files in '{output_dir}':\")\n",
    "# saved_files = [\n",
    "#     \"processed_expression_FXS_OG.csv (genes x samples)\",\n",
    "#     \"processed_methylation_FXS_OG.csv (probes x samples)\", \n",
    "#     \"processed_cnv_FXS_OG.csv (regions x samples)\",\n",
    "#     \"processed_expression_SXF_OG.csv (samples x genes)\",\n",
    "#     \"processed_methylation_SXF_OG.csv (samples x probes)\",\n",
    "#     \"processed_cnv_SXF_OG.csv (samples x regions)\",\n",
    "#     \"processed_phenotype_FXS_OG.csv\",\n",
    "#     \"processed_labels_3Omics_OG.csv\",\n",
    "#     \"subtype_mapping.csv\",\n",
    "#     \"preprocessing_summary.txt\"\n",
    "# ]\n",
    "\n",
    "# for file in saved_files:\n",
    "#     print(f\"   üìÑ {file}\")\n",
    "\n",
    "# print(\"\\nüéâ Data export completed successfully!\")\n",
    "# print(\"üöÄ Ready for multi-omics integration and machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4feb1",
   "metadata": {},
   "source": [
    "## 12. Preprocessing Pipeline Summary\n",
    "\n",
    "### üìä **Final Dataset Overview:**\n",
    "- **Expression Data**: Log2-transformed TPM values, Z-score standardized\n",
    "- **Methylation Data**: Beta values (0-1), no scaling to preserve biological meaning  \n",
    "- **Copy Number Data**: Absolute copy numbers (0-7), converted to log2 ratios, variable regions only\n",
    "- **Subtype Labels**: 4 sarcoma subtypes encoded as 0-3\n",
    "\n",
    "### üîß **Processing Strategy:**\n",
    "1. **Sample Alignment**: Matched samples across all omics platforms\n",
    "2. **Quality Filtering**: Removed high-missing features and low-variance regions\n",
    "3. **Biologically-Informed Imputation**: Appropriate strategies per omics type\n",
    "4. **Scaling Strategy**: Standardized where beneficial, preserved ranges where meaningful\n",
    "5. **Feature Selection**: Focused on variable and informative features\n",
    "\n",
    "### üéØ **Ready for:**\n",
    "- Multi-omics integration methods (MOFA, iCluster, etc.)\n",
    "- Machine learning classification\n",
    "- Deep learning models\n",
    "- Graph neural networks\n",
    "- Survival analysis\n",
    "\n",
    "### üìà **Quality Assurance:**\n",
    "- ‚úÖ No missing values in final datasets\n",
    "- ‚úÖ Biologically plausible value ranges\n",
    "- ‚úÖ Consistent sample alignment\n",
    "- ‚úÖ Balanced class representation\n",
    "- ‚úÖ Reproducible preprocessing pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
