{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2844558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0+cu129\n",
      "Device available: CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c4bc7",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load raw TCGA-SARC multi-omics datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b17edada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TCGA-SARC multi-omics datasets...\n",
      "==================================================\n",
      "Raw data shapes:\n",
      "ğŸ“Š Expression data: (60660, 265) (genes x samples)\n",
      "ğŸ§¬ Methylation data: (486427, 269) (CpG sites x samples)\n",
      "ğŸ“ˆ Copy number data: (60623, 248) (genes x samples)\n",
      "ğŸ¥ Clinical data: (272, 78) (samples x features)\n",
      "\n",
      "âœ… Data loading completed!\n",
      "Raw data shapes:\n",
      "ğŸ“Š Expression data: (60660, 265) (genes x samples)\n",
      "ğŸ§¬ Methylation data: (486427, 269) (CpG sites x samples)\n",
      "ğŸ“ˆ Copy number data: (60623, 248) (genes x samples)\n",
      "ğŸ¥ Clinical data: (272, 78) (samples x features)\n",
      "\n",
      "âœ… Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading TCGA-SARC multi-omics datasets...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load multi-omics data\n",
    "expression_data = pd.read_csv('../TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('../TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('../TCGA-SARC.gene-level_absolute.tsv', sep='\\t', index_col=0) # Copy number variations (absolute)\n",
    "\n",
    "# Load clinical data with error handling\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Initial load failed ({e}), attempting with error handling...\")\n",
    "    phenotype_data = pd.read_csv('../TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Raw data shapes:\")\n",
    "print(f\"ğŸ“Š Expression data: {expression_data.shape} (genes x samples)\")\n",
    "print(f\"ğŸ§¬ Methylation data: {methylation_data.shape} (CpG sites x samples)\")\n",
    "print(f\"ğŸ“ˆ Copy number data: {copy_number_data.shape} (genes x samples)\")\n",
    "print(f\"ğŸ¥ Clinical data: {phenotype_data.shape} (samples x features)\")\n",
    "\n",
    "print(\"\\nâœ… Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc85cc0",
   "metadata": {},
   "source": [
    "## 3. Sample Matching & Quality Control\n",
    "Identify common samples across all omics platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1acea1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample matching and quality assessment...\n",
      "==================================================\n",
      "Sample counts per modality:\n",
      "ğŸ§¬ Expression samples: 265\n",
      "ğŸ”¬ Methylation samples: 269\n",
      "ğŸ“Š CNV samples: 248\n",
      "ğŸ¥ Clinical samples: 272\n",
      "\n",
      "ğŸ¯ Common samples across all omics: 246\n",
      "\n",
      "ğŸ“ Filtered data shapes:\n",
      "Expression: (60660, 246)\n",
      "Methylation: (486427, 246)\n",
      "Copy Number: (60623, 246)\n",
      "Clinical: (246, 78)\n",
      "\n",
      "âœ… Sample matching completed!\n",
      "\n",
      "ğŸ“ Filtered data shapes:\n",
      "Expression: (60660, 246)\n",
      "Methylation: (486427, 246)\n",
      "Copy Number: (60623, 246)\n",
      "Clinical: (246, 78)\n",
      "\n",
      "âœ… Sample matching completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample matching and quality assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check sample overlap between different omics data\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "\n",
    "print(\"Sample counts per modality:\")\n",
    "print(f\"ğŸ§¬ Expression samples: {len(samples_expression)}\")\n",
    "print(f\"ğŸ”¬ Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"ğŸ“Š CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"ğŸ¥ Clinical samples: {len(samples_clinical)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical))\n",
    "print(f\"\\nğŸ¯ Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]\n",
    "\n",
    "print(f\"\\nğŸ“ Filtered data shapes:\")\n",
    "print(f\"Expression: {expression_data.shape}\")\n",
    "print(f\"Methylation: {methylation_data.shape}\")\n",
    "print(f\"Copy Number: {copy_number_data.shape}\")\n",
    "print(f\"Clinical: {phenotype_data.shape}\")\n",
    "\n",
    "print(\"\\nâœ… Sample matching completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5784a6",
   "metadata": {},
   "source": [
    "## 4. Missing Value Assessment\n",
    "Comprehensive analysis of missing values across all omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fce29fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value assessment...\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Expression Data:\n",
      "   Total values: 14,922,360\n",
      "   Missing values: 0\n",
      "   Missing percentage: 0.00%\n",
      "   âœ… No missing values found\n",
      "\n",
      "ğŸ“Š Methylation Data:\n",
      "   Total values: 119,661,042\n",
      "   Missing values: 19,622,910\n",
      "   Missing percentage: 16.40%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“Š Copy Number Data:\n",
      "   Total values: 14,913,258\n",
      "   Missing values: 994,360\n",
      "   Missing percentage: 6.67%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“Š Phenotype Data:\n",
      "   Total values: 19,188\n",
      "   Missing values: 3,960\n",
      "   Missing percentage: 20.64%\n",
      "   âš ï¸  Contains missing values - preprocessing required\n",
      "\n",
      "ğŸ“‹ MISSING VALUE SUMMARY:\n",
      "Expression: 0 (0.00%)\n",
      "Methylation: 19,622,910 (16.40%)\n",
      "Copy Number: 994,360 (6.67%)\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Phenotype: 3,960 (20.64%)\n",
      "\n",
      "âœ… Missing value assessment completed!\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Phenotype: 3,960 (20.64%)\n",
      "\n",
      "âœ… Missing value assessment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value assessment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for null values in each omics modality\n",
    "def assess_missing_values(data, name):\n",
    "    total_values = data.size\n",
    "    missing_count = data.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / total_values) * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {name}:\")\n",
    "    print(f\"   Total values: {total_values:,}\")\n",
    "    print(f\"   Missing values: {missing_count:,}\")\n",
    "    print(f\"   Missing percentage: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"   âš ï¸  Contains missing values - preprocessing required\")\n",
    "    else:\n",
    "        print(f\"   âœ… No missing values found\")\n",
    "    \n",
    "    return missing_count, missing_percentage\n",
    "\n",
    "# Assess each omics modality\n",
    "expr_missing, expr_pct = assess_missing_values(expression_data, \"Expression Data\")\n",
    "meth_missing, meth_pct = assess_missing_values(methylation_data, \"Methylation Data\")\n",
    "cnv_missing, cnv_pct = assess_missing_values(copy_number_data, \"Copy Number Data\")\n",
    "pheno_missing, pheno_pct = assess_missing_values(phenotype_data, \"Phenotype Data\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nğŸ“‹ MISSING VALUE SUMMARY:\")\n",
    "print(f\"Expression: {expr_missing:,} ({expr_pct:.2f}%)\")\n",
    "print(f\"Methylation: {meth_missing:,} ({meth_pct:.2f}%)\")\n",
    "print(f\"Copy Number: {cnv_missing:,} ({cnv_pct:.2f}%)\")\n",
    "max_value = copy_number_data.max().max()\n",
    "min_value = copy_number_data.min().min()\n",
    "\n",
    "print(f\"Maximum CNV value: {max_value}\")\n",
    "print(f\"Minimum CNV value: {min_value}\")\n",
    "print()\n",
    "print(f\"Phenotype: {pheno_missing:,} ({pheno_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Missing value assessment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4e49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Log2 transform\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "# Methylation data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Droping probes with more than 20% missing values \n",
    "methylation_data = methylation_data.dropna(thresh=0.8 * methylation_data.shape[1], axis=0)\n",
    "\n",
    "# fill na with probe wise median\n",
    "methylation_data = methylation_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "\n",
    "# Remove low-variance methylation probes\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_filtered = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_data.T).T,\n",
    "    index=methylation_data.index[selector.get_support()],\n",
    "    columns=methylation_data.columns\n",
    ")\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_meth = StandardScaler()\n",
    "methylation_scaled = pd.DataFrame(\n",
    "    scaler_meth.fit_transform(methylation_filtered.T).T,\n",
    "    index=methylation_filtered.index,\n",
    "    columns=methylation_filtered.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Copy number data preprocessing -------------------------------------------------->\n",
    "\n",
    "\n",
    "# Drop genes with >20% missing values\n",
    "gene_missing_threshold = 0.2\n",
    "copy_number_data_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "\n",
    "# filling null values with gene-wise median\n",
    "copy_number_imputed = copy_number_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_cnv = StandardScaler()\n",
    "copy_number_scaled = pd.DataFrame(\n",
    "    scaler_cnv.fit_transform(copy_number_imputed.T).T,\n",
    "    index=copy_number_imputed.index,\n",
    "    columns=copy_number_imputed.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c10026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Processing Methylation Data...\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# print(f\"ğŸ“Š Original shape: {methylation_data.shape}\")\n",
    "# print(f\"ğŸ“Š Value range: [{methylation_data.min().min():.3f}, {methylation_data.max().max():.3f}]\")\n",
    "# print(f\"ğŸ“Š Missing values: {methylation_data.isnull().sum().sum():,}\")\n",
    "\n",
    "# # Step 1: Drop probes with >20% missing values (80% threshold)\n",
    "# print(\"ğŸ”„ Removing probes with >20% missing values...\")\n",
    "# before_filter = methylation_data.shape[0]\n",
    "# methylation_data = methylation_data.dropna(thresh=0.80 * methylation_data.shape[1], axis=0)\n",
    "# after_filter = methylation_data.shape[0]\n",
    "# removed_probes = before_filter - after_filter\n",
    "# print(f\"ğŸ“Š Removed {removed_probes:,} probes ({removed_probes/before_filter*100:.1f}%)\")\n",
    "# print(f\"ğŸ“Š Remaining probes: {after_filter:,}\")\n",
    "\n",
    "# # Step 2: Impute remaining missing values probe-wise (mean across samples)\n",
    "# print(\"ğŸ”„ Imputing remaining missing values with probe-wise mean...\")\n",
    "# methylation_data = methylation_data.fillna(methylation_data.mean(axis=1))\n",
    "# print(f\"âœ… Missing values after imputation: {methylation_data.isnull().sum().sum()}\")\n",
    "\n",
    "# # Step 3: Remove low-variance probes (threshold = 0.01)\n",
    "# print(\"ğŸ”„ Removing low-variance probes...\")\n",
    "# before_variance = methylation_data.shape[0]\n",
    "# selector = VarianceThreshold(threshold=0.01)\n",
    "# methylation_filtered = pd.DataFrame(\n",
    "#     selector.fit_transform(methylation_data.T).T,\n",
    "#     index=methylation_data.index[selector.get_support()],\n",
    "#     columns=methylation_data.columns\n",
    "# )\n",
    "# after_variance = methylation_filtered.shape[0]\n",
    "# removed_low_var = before_variance - after_variance\n",
    "# print(f\"ğŸ“Š Removed {removed_low_var:,} low-variance probes ({removed_low_var/before_variance*100:.1f}%)\")\n",
    "\n",
    "# # Step 4: Handle any NaNs introduced by VarianceThreshold\n",
    "# if methylation_filtered.isnull().sum().sum() > 0:\n",
    "#     print(f\"ğŸ”„ Filling {methylation_filtered.isnull().sum().sum()} NaNs after variance filtering...\")\n",
    "#     methylation_filtered = methylation_filtered.fillna(methylation_filtered.mean(axis=1))\n",
    "\n",
    "# # Step 5: NO SCALING - Keep original beta values (0-1 range)\n",
    "# print(\"ğŸ“‹ Preserving original beta values (no scaling applied)\")\n",
    "# methylation_scaled = methylation_filtered.copy()\n",
    "\n",
    "# print(f\"ğŸ“Š Final shape: {methylation_scaled.shape}\")\n",
    "# print(f\"ğŸ“Š Final range: [{methylation_scaled.min().min():.3f}, {methylation_scaled.max().max():.3f}]\")\n",
    "# print(f\"ğŸ“Š Missing values: {methylation_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "# print(\"\\nâœ… Methylation data preprocessing completed!\")\n",
    "# print(\"ğŸ§¬ Beta values preserved for biological interpretability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c52b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Phenotype Data...\n",
      "==================================================\n",
      "ğŸ¯ Target column: 'primary_diagnosis.diagnoses'\n",
      "ğŸ“Š Original subtype distribution:\n",
      "   âœ… Leiomyosarcoma, NOS: 96\n",
      "   âœ… Dedifferentiated liposarcoma: 53\n",
      "   âœ… Undifferentiated sarcoma: 34\n",
      "   âœ… Fibromyxosarcoma: 22\n",
      "   âŒ Malignant fibrous histiocytoma: 11\n",
      "   âŒ Malignant peripheral nerve sheath tumor: 10\n",
      "   âŒ Synovial sarcoma, spindle cell: 6\n",
      "   âŒ Giant cell sarcoma: 3\n",
      "   âŒ Myxoid leiomyosarcoma: 2\n",
      "   âŒ Pleomorphic liposarcoma: 2\n",
      "   âŒ Synovial sarcoma, NOS: 2\n",
      "   âŒ Synovial sarcoma, biphasic: 2\n",
      "   âŒ Aggressive fibromatosis: 1\n",
      "   âŒ Liposarcoma, well differentiated: 1\n",
      "   âŒ Abdominal fibromatosis: 1\n",
      "\n",
      "ğŸ”„ Filtering to selected subtypes...\n",
      "ğŸ“Š Removed 41 samples (16.7%)\n",
      "ğŸ“Š Remaining samples: 205\n",
      "\n",
      "ğŸ” Missing values in subtype column: 0\n",
      "âœ… No missing subtypes found\n",
      "ğŸ“Š Clean phenotype data shape: (205, 78)\n",
      "\n",
      "ğŸ”„ Encoding subtypes as numeric labels...\n",
      "ğŸ“‹ Subtype encoding mapping:\n",
      "   0: Dedifferentiated liposarcoma\n",
      "   1: Fibromyxosarcoma\n",
      "   2: Leiomyosarcoma, NOS\n",
      "   3: Undifferentiated sarcoma\n",
      "\n",
      "ğŸ“Š Encoded subtype distribution:\n",
      "   Class 0: 53 samples (Dedifferentiated liposarcoma)\n",
      "   Class 1: 22 samples (Fibromyxosarcoma)\n",
      "   Class 2: 96 samples (Leiomyosarcoma, NOS)\n",
      "   Class 3: 34 samples (Undifferentiated sarcoma)\n",
      "\n",
      "âœ… Phenotype data processing completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Phenotype Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define subtype column and selected subtypes\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "selected_subtypes = [\n",
    "    'Leiomyosarcoma, NOS',\n",
    "    'Dedifferentiated liposarcoma',\n",
    "    'Undifferentiated sarcoma',\n",
    "    'Fibromyxosarcoma'\n",
    "]\n",
    "\n",
    "print(f\"ğŸ¯ Target column: '{subtype_column}'\")\n",
    "print(f\"ğŸ“Š Original subtype distribution:\")\n",
    "subtype_counts = phenotype_data[subtype_column].value_counts()\n",
    "for subtype, count in subtype_counts.items():\n",
    "    marker = \"âœ…\" if subtype in selected_subtypes else \"âŒ\"\n",
    "    print(f\"   {marker} {subtype}: {count}\")\n",
    "\n",
    "# Filter to selected subtypes only\n",
    "print(f\"\\nğŸ”„ Filtering to selected subtypes...\")\n",
    "before_filter = len(phenotype_data)\n",
    "phenotype_data = phenotype_data[phenotype_data[subtype_column].isin(selected_subtypes)]\n",
    "after_filter = len(phenotype_data)\n",
    "removed_samples = before_filter - after_filter\n",
    "print(f\"ğŸ“Š Removed {removed_samples} samples ({removed_samples/before_filter*100:.1f}%)\")\n",
    "print(f\"ğŸ“Š Remaining samples: {after_filter}\")\n",
    "\n",
    "# Check for missing subtypes\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"\\nğŸ” Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    print(\"ğŸ”„ Removing samples with missing subtypes...\")\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"ğŸ“Š Removed {missing_subtypes} samples with missing subtypes\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"âœ… No missing subtypes found\")\n",
    "\n",
    "print(f\"ğŸ“Š Clean phenotype data shape: {phenotype_data_clean.shape}\")\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "print(\"\\nğŸ”„ Encoding subtypes as numeric labels...\")\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create and display encoding mapping\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"ğŸ“‹ Subtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"   {encoded}: {subtype}\")\n",
    "\n",
    "# Convert to pandas Series for easy handling\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nğŸ“Š Encoded subtype distribution:\")\n",
    "encoded_counts = subtype_encoded.value_counts().sort_index()\n",
    "for label, count in encoded_counts.items():\n",
    "    subtype_name = label_encoder.classes_[label]\n",
    "    print(f\"   Class {label}: {count} samples ({subtype_name})\")\n",
    "\n",
    "print(\"\\nâœ… Phenotype data processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d7ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Sample Alignment...\n",
      "==================================================\n",
      "ğŸ”„ Updating common samples: 246 â†’ 205\n",
      "ğŸ“Š Removed 41 samples (missing subtypes or not in selected subtypes)\n",
      "\n",
      "ğŸ”„ Aligning all datasets to valid samples...\n",
      "\n",
      "ğŸ“ Final aligned data shapes:\n",
      "   Expression: (60660, 205) (genes x samples)\n",
      "   Methylation: (220147, 205) (probes x samples)\n",
      "   Copy Number: (56756, 205) (regions x samples)\n",
      "   Phenotype: (205, 78) (samples x features)\n",
      "   Subtypes: 205 (samples)\n",
      "   Common samples: 205\n",
      "\n",
      "âœ… All datasets have consistent sample alignment!\n",
      "\n",
      "âœ… Final sample alignment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Sample Alignment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "print(f\"ğŸ”„ Updating common samples: {len(common_samples)} â†’ {len(valid_samples)}\")\n",
    "removed_samples = len(common_samples) - len(valid_samples)\n",
    "print(f\"ğŸ“Š Removed {removed_samples} samples (missing subtypes or not in selected subtypes)\")\n",
    "\n",
    "# Align all datasets to valid samples\n",
    "print(\"\\nğŸ”„ Aligning all datasets to valid samples...\")\n",
    "expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "methylation_scaled = methylation_scaled[valid_samples]\n",
    "copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "phenotype_data_clean = phenotype_data_clean.loc[valid_samples]\n",
    "common_samples = valid_samples\n",
    "\n",
    "# Final shape verification\n",
    "print(f\"\\nğŸ“ Final aligned data shapes:\")\n",
    "print(f\"   Expression: {expression_data_scaled.shape} (genes x samples)\")\n",
    "print(f\"   Methylation: {methylation_scaled.shape} (probes x samples)\")\n",
    "print(f\"   Copy Number: {copy_number_scaled.shape} (regions x samples)\")\n",
    "print(f\"   Phenotype: {phenotype_data_clean.shape} (samples x features)\")\n",
    "print(f\"   Subtypes: {len(subtype_encoded)} (samples)\")\n",
    "print(f\"   Common samples: {len(common_samples)}\")\n",
    "\n",
    "# Verify sample consistency\n",
    "sample_sets = [\n",
    "    set(expression_data_scaled.columns),\n",
    "    set(methylation_scaled.columns),\n",
    "    set(copy_number_scaled.columns),\n",
    "    set(subtype_encoded.index),\n",
    "    set(phenotype_data_clean.index)\n",
    "]\n",
    "\n",
    "all_consistent = all(s == sample_sets[0] for s in sample_sets)\n",
    "if all_consistent:\n",
    "    print(\"\\nâœ… All datasets have consistent sample alignment!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Warning: Sample alignment inconsistency detected!\")\n",
    "\n",
    "print(\"\\nâœ… Final sample alignment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6053d0",
   "metadata": {},
   "source": [
    "## 10. Data Quality Verification\n",
    "Final quality checks before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb03bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Verification...\n",
      "==================================================\n",
      "\n",
      "ğŸ” Expression Data (Standardized):\n",
      "   Shape: (60660, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-10.986, 15.652]\n",
      "   âœ… No infinite values\n",
      "\n",
      "ğŸ” Methylation Data (Beta Values):\n",
      "   Shape: (220147, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-9.054, 9.341]\n",
      "   âš ï¸  Values outside expected range (0, 1)\n",
      "   âœ… No infinite values\n",
      "\n",
      "ğŸ” Copy Number Data (Log2 Ratios):\n",
      "   Shape: (56756, 205)\n",
      "   Missing values: 0\n",
      "   Data type: float64\n",
      "   Value range: [-2.967, 6.638]\n",
      "   âœ… No infinite values\n",
      "\n",
      "ğŸ“Š PREPROCESSING SUMMARY:\n",
      "   Total samples: 205\n",
      "   Expression features: 60,660\n",
      "   Methylation features: 220,147\n",
      "   Copy number features: 56,756\n",
      "   Total features: 337,563\n",
      "   Number of classes: 4\n",
      "\n",
      "âœ… Data quality verification completed!\n",
      "ğŸ‰ All datasets are ready for machine learning and integration methods!\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Quality Verification...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def verify_data_quality(data, name, expected_range=None):\n",
    "    print(f\"\\nğŸ” {name}:\")\n",
    "    print(f\"   Shape: {data.shape}\")\n",
    "    print(f\"   Missing values: {data.isnull().sum().sum():,}\")\n",
    "    print(f\"   Data type: {data.dtypes.iloc[0] if hasattr(data, 'dtypes') else type(data.iloc[0] if hasattr(data, 'iloc') else data[0])}\")\n",
    "    \n",
    "    if hasattr(data, 'min') and hasattr(data, 'max'):\n",
    "        min_val = data.min().min() if hasattr(data.min(), 'min') else data.min()\n",
    "        max_val = data.max().max() if hasattr(data.max(), 'max') else data.max()\n",
    "        print(f\"   Value range: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "        \n",
    "        if expected_range:\n",
    "            if expected_range[0] <= min_val <= max_val <= expected_range[1]:\n",
    "                print(f\"   âœ… Values within expected range {expected_range}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  Values outside expected range {expected_range}\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    if hasattr(data, 'values'):\n",
    "        inf_count = np.isinf(data.values).sum()\n",
    "        if inf_count > 0:\n",
    "            print(f\"   âš ï¸  Contains {inf_count} infinite values\")\n",
    "        else:\n",
    "            print(f\"   âœ… No infinite values\")\n",
    "\n",
    "# Verify each dataset\n",
    "verify_data_quality(expression_data_scaled, \"Expression Data (Standardized)\")\n",
    "verify_data_quality(methylation_scaled, \"Methylation Data (Beta Values)\", expected_range=(0, 1))\n",
    "verify_data_quality(copy_number_scaled, \"Copy Number Data (Log2 Ratios)\")\n",
    "# verify_data_quality(subtype_encoded, \"Subtype Labels\", expected_range=(0, len(label_encoder.classes_)-1))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nğŸ“Š PREPROCESSING SUMMARY:\")\n",
    "print(f\"   Total samples: {len(common_samples)}\")\n",
    "print(f\"   Expression features: {expression_data_scaled.shape[0]:,}\")\n",
    "print(f\"   Methylation features: {methylation_scaled.shape[0]:,}\")\n",
    "print(f\"   Copy number features: {copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Total features: {expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0]:,}\")\n",
    "print(f\"   Number of classes: {len(np.unique(subtype_encoded))}\")\n",
    "\n",
    "print(\"\\nâœ… Data quality verification completed!\")\n",
    "print(\"ğŸ‰ All datasets are ready for machine learning and integration methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca1524",
   "metadata": {},
   "source": [
    "## 11. Data Export\n",
    "Save processed datasets for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c06bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Processed Data...\n",
      "==================================================\n",
      "ğŸ”„ Saving processed datasets...\n",
      "âœ… Main datasets saved (features as rows)\n",
      "ğŸ”„ Creating and saving transposed versions for ML...\n",
      "âœ… Transposed datasets saved (samples as rows)\n",
      "ğŸ”„ Saving metadata...\n",
      "âœ… Metadata saved\n",
      "\n",
      "ğŸ“ Saved files in '../Updated_model_nd_dataset/':\n",
      "   ğŸ“„ processed_expression_FXS_OG.csv (genes x samples)\n",
      "   ğŸ“„ processed_methylation_FXS_OG.csv (probes x samples)\n",
      "   ğŸ“„ processed_cnv_FXS_OG.csv (regions x samples)\n",
      "   ğŸ“„ processed_expression_SXF_OG.csv (samples x genes)\n",
      "   ğŸ“„ processed_methylation_SXF_OG.csv (samples x probes)\n",
      "   ğŸ“„ processed_cnv_SXF_OG.csv (samples x regions)\n",
      "   ğŸ“„ processed_phenotype_FXS_OG.csv\n",
      "   ğŸ“„ processed_labels_3Omics_OG.csv\n",
      "   ğŸ“„ subtype_mapping.csv\n",
      "   ğŸ“„ preprocessing_summary.txt\n",
      "\n",
      "ğŸ‰ Data export completed successfully!\n",
      "ğŸš€ Ready for multi-omics integration and machine learning!\n"
     ]
    }
   ],
   "source": [
    "# print(\"Exporting Processed Data...\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# # Define output directory\n",
    "# output_dir = \"../Updated_model_nd_dataset/\"\n",
    "\n",
    "# # Save processed datasets\n",
    "# print(\"ğŸ”„ Saving processed datasets...\")\n",
    "\n",
    "# # Save main processed files (features as rows, samples as columns)\n",
    "# expression_data_scaled.to_csv(f\"{output_dir}processed_expression_FXS_OG.csv\")\n",
    "# methylation_scaled.to_csv(f\"{output_dir}processed_methylation_FXS_OG.csv\")\n",
    "# copy_number_scaled.to_csv(f\"{output_dir}processed_cnv_FXS_OG.csv\")\n",
    "# phenotype_data_clean.to_csv(f\"{output_dir}processed_phenotype_FXS_OG.csv\")\n",
    "# subtype_encoded.to_csv(f\"{output_dir}processed_labels_3Omics_FXS_OG.csv\", header=True)\n",
    "\n",
    "# print(\"âœ… Main datasets saved (features as rows)\")\n",
    "\n",
    "# # Save transposed versions for ML models (samples as rows, features as columns)\n",
    "# print(\"ğŸ”„ Creating and saving transposed versions for ML...\")\n",
    "\n",
    "# expression_data_scaled.T.to_csv(f\"{output_dir}processed_expression_SXF_OG.csv\")\n",
    "# methylation_scaled.T.to_csv(f\"{output_dir}processed_methylation_SXF_OG.csv\")\n",
    "# copy_number_scaled.T.to_csv(f\"{output_dir}processed_cnv_SXF_OG.csv\")\n",
    "\n",
    "# print(\"âœ… Transposed datasets saved (samples as rows)\")\n",
    "\n",
    "# # Save metadata and mappings\n",
    "# print(\"ğŸ”„ Saving metadata...\")\n",
    "\n",
    "# # Save subtype mapping\n",
    "# mapping_df = pd.DataFrame([\n",
    "#     {'encoded_label': k, 'subtype_name': v} \n",
    "#     for v, k in subtype_mapping.items()\n",
    "# ])\n",
    "# mapping_df.to_csv(f\"{output_dir}subtype_mapping.csv\", index=False)\n",
    "\n",
    "# # Save processing summary\n",
    "# summary_info = {\n",
    "#     'total_samples': len(common_samples),\n",
    "#     'expression_features': expression_data_scaled.shape[0],\n",
    "#     'methylation_features': methylation_scaled.shape[0],\n",
    "#     'copy_number_features': copy_number_scaled.shape[0],\n",
    "#     'total_features': expression_data_scaled.shape[0] + methylation_scaled.shape[0] + copy_number_scaled.shape[0],\n",
    "#     'num_classes': len(np.unique(subtype_encoded)),\n",
    "#     'class_names': list(label_encoder.classes_)\n",
    "# }\n",
    "\n",
    "# with open(f\"{output_dir}preprocessing_summary.txt\", 'w') as f:\n",
    "#     f.write(\"TCGA-SARC Multi-Omics Preprocessing Summary\\n\")\n",
    "#     f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "#     for key, value in summary_info.items():\n",
    "#         f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "# print(\"âœ… Metadata saved\")\n",
    "\n",
    "# # Display saved files\n",
    "# print(f\"\\nğŸ“ Saved files in '{output_dir}':\")\n",
    "# saved_files = [\n",
    "#     \"processed_expression_FXS_OG.csv (genes x samples)\",\n",
    "#     \"processed_methylation_FXS_OG.csv (probes x samples)\", \n",
    "#     \"processed_cnv_FXS_OG.csv (regions x samples)\",\n",
    "#     \"processed_expression_SXF_OG.csv (samples x genes)\",\n",
    "#     \"processed_methylation_SXF_OG.csv (samples x probes)\",\n",
    "#     \"processed_cnv_SXF_OG.csv (samples x regions)\",\n",
    "#     \"processed_phenotype_FXS_OG.csv\",\n",
    "#     \"processed_labels_3Omics_OG.csv\",\n",
    "#     \"subtype_mapping.csv\",\n",
    "#     \"preprocessing_summary.txt\"\n",
    "# ]\n",
    "\n",
    "# for file in saved_files:\n",
    "#     print(f\"   ğŸ“„ {file}\")\n",
    "\n",
    "# print(\"\\nğŸ‰ Data export completed successfully!\")\n",
    "# print(\"ğŸš€ Ready for multi-omics integration and machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4feb1",
   "metadata": {},
   "source": [
    "## 12. Preprocessing Pipeline Summary\n",
    "\n",
    "### ğŸ“Š **Final Dataset Overview:**\n",
    "- **Expression Data**: Log2-transformed TPM values, Z-score standardized\n",
    "- **Methylation Data**: Beta values (0-1), no scaling to preserve biological meaning  \n",
    "- **Copy Number Data**: Absolute copy numbers (0-7), converted to log2 ratios, variable regions only\n",
    "- **Subtype Labels**: 4 sarcoma subtypes encoded as 0-3\n",
    "\n",
    "### ğŸ”§ **Processing Strategy:**\n",
    "1. **Sample Alignment**: Matched samples across all omics platforms\n",
    "2. **Quality Filtering**: Removed high-missing features and low-variance regions\n",
    "3. **Biologically-Informed Imputation**: Appropriate strategies per omics type\n",
    "4. **Scaling Strategy**: Standardized where beneficial, preserved ranges where meaningful\n",
    "5. **Feature Selection**: Focused on variable and informative features\n",
    "\n",
    "### ğŸ¯ **Ready for:**\n",
    "- Multi-omics integration methods (MOFA, iCluster, etc.)\n",
    "- Machine learning classification\n",
    "- Deep learning models\n",
    "- Graph neural networks\n",
    "- Survival analysis\n",
    "\n",
    "### ğŸ“ˆ **Quality Assurance:**\n",
    "- âœ… No missing values in final datasets\n",
    "- âœ… Biologically plausible value ranges\n",
    "- âœ… Consistent sample alignment\n",
    "- âœ… Balanced class representation\n",
    "- âœ… Reproducible preprocessing pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
