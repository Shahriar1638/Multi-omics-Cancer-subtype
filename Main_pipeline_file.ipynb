{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6b0332",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751acfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEOW\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "C:\\Users\\MEOW\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "C:\\Users\\MEOW\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "C:\\Users\\MEOW\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "C:\\Users\\MEOW\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab1fb1",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ce09bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TCGA-SARC.star_tpm.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m expression_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTCGA-SARC.star_tpm.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Gene expression (TPM)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m methylation_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCGA-SARC.methylation450.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# DNA methylation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m copy_number_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCGA-SARC.gene-level_absolute.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Gene-level copy number (ABSOLUTE)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TCGA-SARC.star_tpm.tsv'"
     ]
    }
   ],
   "source": [
    "expression_data = pd.read_csv('TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('TCGA-SARC.gene-level_absolute.tsv', sep='\\t', index_col=0)  # Gene-level copy number (ABSOLUTE)\n",
    "protein_data = pd.read_csv('TCGA-SARC.protein.tsv', sep='\\t', index_col=0)  # Protein expression\n",
    "\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(\"Error while loading phenotype_data:\", e)\n",
    "    with open('TCGA-SARC.clinical.tsv', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                pd.read_csv(pd.compat.StringIO(line), sep='\\t')\n",
    "            except Exception as row_e:\n",
    "                print(f\"Error in line {i}: {row_e}\")\n",
    "    phenotype_data = pd.read_csv('TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"Expression data: {expression_data.shape}\")\n",
    "print(f\"Methylation data: {methylation_data.shape}\")\n",
    "print(f\"Copy number data: {copy_number_data.shape}\")\n",
    "print(f\"Protein data: {protein_data.shape}\")\n",
    "print(f\"Phenotype data: {phenotype_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7372a",
   "metadata": {},
   "source": [
    "# Sample Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in phenotype data:\n",
      "days_to_birth.demographic                                      1\n",
      "year_of_birth.demographic                                      4\n",
      "days_to_death.demographic                                    170\n",
      "year_of_death.demographic                                    195\n",
      "entity_submitter_id.annotations                              254\n",
      "notes.annotations                                            254\n",
      "submitter_id.annotations                                     254\n",
      "classification.annotations                                   254\n",
      "entity_id.annotations                                        254\n",
      "created_datetime.annotations                                 254\n",
      "annotation_id.annotations                                    254\n",
      "entity_type.annotations                                      254\n",
      "updated_datetime.annotations                                 254\n",
      "case_id.annotations                                          254\n",
      "state.annotations                                            254\n",
      "category.annotations                                         254\n",
      "status.annotations                                           254\n",
      "case_submitter_id.annotations                                254\n",
      "days_to_last_follow_up.diagnoses                              77\n",
      "age_at_diagnosis.diagnoses                                     1\n",
      "year_of_diagnosis.diagnoses                                    4\n",
      "age_at_earliest_diagnosis.diagnoses.xena_derived               1\n",
      "age_at_earliest_diagnosis_in_years.diagnoses.xena_derived      1\n",
      "days_to_collection.samples                                     4\n",
      "pathology_report_uuid.samples                                  6\n",
      "annotations.samples                                          266\n",
      "dtype: int64\n",
      "\n",
      "Checking sample overlap between different omics data:\n",
      "Sample overlap:\n",
      "Expression samples: 265\n",
      "Methylation samples: 269\n",
      "CNV samples: 248\n",
      "Clinical samples: 272\n",
      "Protein samples: 226\n",
      "Common samples across all omics: 210\n"
     ]
    }
   ],
   "source": [
    "# subtype_columns = [col for col in phenotype_data.columns if any(keyword in col.lower() \n",
    "#                    for keyword in ['subtype', 'histology', 'type', 'classification'])]\n",
    "\n",
    "# print(\"Subtype-related columns:\")\n",
    "# for col in subtype_columns:\n",
    "#     print(f\"- {col}\")\n",
    "#     print(phenotype_data[col].value_counts())\n",
    "#     print()\n",
    "\n",
    "\n",
    "print(\"Checking for missing values in phenotype data:\")\n",
    "missing_values = phenotype_data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "print()\n",
    "print(\"Checking sample overlap between different omics data:\")\n",
    "\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "samples_protein = set(protein_data.columns)\n",
    "print(\"Sample overlap:\")\n",
    "print(f\"Expression samples: {len(samples_expression)}\")\n",
    "print(f\"Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"Clinical samples: {len(samples_clinical)}\")\n",
    "print(f\"Protein samples: {len(samples_protein)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical, samples_protein))\n",
    "print(f\"Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "protein_data = protein_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba21134",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f5c64",
   "metadata": {},
   "source": [
    "### Check Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values in expression data:\n",
      "No null values found in expression data.\n",
      "\n",
      "Checking for null values in methylation data:\n",
      "Methylation data contains 16814049 null values.\n",
      "\n",
      "Checking for null values in copy number data:\n",
      "Copy number data contains 855388 null values.\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Checking for null values in protein data:\n",
      "Protein data contains 6300 null values.\n",
      "\n",
      "Checking for null values in phenotype data:\n",
      "Phenotype data contains 3389 null values.\n"
     ]
    }
   ],
   "source": [
    "#Check for null values of expression data\n",
    "print(\"Checking for null values in expression data:\")\n",
    "null_expression = expression_data.isnull().sum().sum()\n",
    "if null_expression > 0:\n",
    "    print(f\"Expression data contains {null_expression} null values.\")\n",
    "else:   \n",
    "    print(\"No null values found in expression data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in methylation data\n",
    "print(\"Checking for null values in methylation data:\")\n",
    "null_methylation = methylation_data.isnull().sum().sum()\n",
    "if null_methylation > 0:\n",
    "    print(f\"Methylation data contains {null_methylation} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in methylation data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in copy number data\n",
    "print(\"Checking for null values in copy number data:\")\n",
    "null_copy_number = copy_number_data.isnull().sum().sum()\n",
    "if null_copy_number > 0:\n",
    "    print(f\"Copy number data contains {null_copy_number} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in copy number data.\")\n",
    "max_value = copy_number_data.max().max()\n",
    "min_value = copy_number_data.min().min()\n",
    "\n",
    "print(f\"Maximum CNV value: {max_value}\")\n",
    "print(f\"Minimum CNV value: {min_value}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in protein data\n",
    "print(\"Checking for null values in protein data:\")\n",
    "null_protein = protein_data.isnull().sum().sum()\n",
    "if null_protein > 0:\n",
    "    print(f\"Protein data contains {null_protein} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in protein data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in phenotype data\n",
    "print(\"Checking for null values in phenotype data:\")\n",
    "null_phenotype = phenotype_data.isnull().sum().sum()\n",
    "if null_phenotype > 0:\n",
    "    print(f\"Phenotype data contains {null_phenotype} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in phenotype data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8d1a5",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Log2 transform\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "# Methylation data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Droping probes with more than 10% missing values \n",
    "methylation_data = methylation_data.dropna(thresh=0.9 * methylation_data.shape[1], axis=0)\n",
    "\n",
    "# fill na with probe wise median\n",
    "methylation_data = methylation_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "\n",
    "# Remove low-variance methylation probes\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_filtered = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_data.T).T,\n",
    "    index=methylation_data.index[selector.get_support()],\n",
    "    columns=methylation_data.columns\n",
    ")\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_meth = StandardScaler()\n",
    "methylation_scaled = pd.DataFrame(\n",
    "    scaler_meth.fit_transform(methylation_filtered.T).T,\n",
    "    index=methylation_filtered.index,\n",
    "    columns=methylation_filtered.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Copy number data preprocessing -------------------------------------------------->\n",
    "\n",
    "\n",
    "# Drop genes with >20% missing values\n",
    "gene_missing_threshold = 0.2\n",
    "copy_number_data_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "\n",
    "# filling null values with gene-wise median\n",
    "copy_number_imputed = copy_number_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_cnv = StandardScaler()\n",
    "copy_number_scaled = pd.DataFrame(\n",
    "    scaler_cnv.fit_transform(copy_number_imputed.T).T,\n",
    "    index=copy_number_imputed.index,\n",
    "    columns=copy_number_imputed.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Protein data preprocessing ------------------------------------------------------>\n",
    "\n",
    "# Drop proteins with >20% missing values\n",
    "protein_missing_threshold = 0.3\n",
    "protein_data_filtered = protein_data.loc[\n",
    "    protein_data.isnull().mean(axis=1) < protein_missing_threshold\n",
    "]\n",
    "# filling null values with protein-wise median\n",
    "protein_imputed = protein_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_protein = StandardScaler()\n",
    "protein_scaled = pd.DataFrame(\n",
    "    scaler_protein.fit_transform(protein_imputed.T).T,\n",
    "    index=protein_imputed.index,\n",
    "    columns=protein_imputed.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'primary_diagnosis.diagnoses' as the subtype column\n",
      "Subtype distribution:\n",
      "primary_diagnosis.diagnoses\n",
      "Leiomyosarcoma, NOS                        76\n",
      "Dedifferentiated liposarcoma               49\n",
      "Undifferentiated sarcoma                   32\n",
      "Fibromyxosarcoma                           20\n",
      "Malignant fibrous histiocytoma             11\n",
      "Malignant peripheral nerve sheath tumor     9\n",
      "Synovial sarcoma, spindle cell              4\n",
      "Giant cell sarcoma                          3\n",
      "Pleomorphic liposarcoma                     2\n",
      "Myxoid leiomyosarcoma                       1\n",
      "Liposarcoma, well differentiated            1\n",
      "Synovial sarcoma, NOS                       1\n",
      "Synovial sarcoma, biphasic                  1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in subtype column: 0\n",
      "No missing subtypes found\n"
     ]
    }
   ],
   "source": [
    "# Phenotype data preprocessing -------------------------------------------------->\n",
    "\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "print(f\"Using '{subtype_column}' as the subtype column\")\n",
    "print(f\"Subtype distribution:\\n{phenotype_data[subtype_column].value_counts()}\")\n",
    "print()\n",
    "\n",
    "# Checking missing values in the subtype column\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"Removed {missing_subtypes} samples with missing subtypes\")\n",
    "    print(f\"Remaining samples: {len(phenotype_data_clean)}\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"No missing subtypes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ecf3c",
   "metadata": {},
   "source": [
    "### Sample matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b789e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtype encoding mapping:\n",
      "  0: Dedifferentiated liposarcoma\n",
      "  1: Fibromyxosarcoma\n",
      "  2: Giant cell sarcoma\n",
      "  3: Leiomyosarcoma, NOS\n",
      "  4: Liposarcoma, well differentiated\n",
      "  5: Malignant fibrous histiocytoma\n",
      "  6: Malignant peripheral nerve sheath tumor\n",
      "  7: Myxoid leiomyosarcoma\n",
      "  8: Pleomorphic liposarcoma\n",
      "  9: Synovial sarcoma, NOS\n",
      "  10: Synovial sarcoma, biphasic\n",
      "  11: Synovial sarcoma, spindle cell\n",
      "  12: Undifferentiated sarcoma\n",
      "\n",
      "Encoded subtype distribution:\n",
      "subtype_encoded\n",
      "0     49\n",
      "1     20\n",
      "2      3\n",
      "3     76\n",
      "4      1\n",
      "5     11\n",
      "6      9\n",
      "7      1\n",
      "8      2\n",
      "9      1\n",
      "10     1\n",
      "11     4\n",
      "12    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final data shapes after phenotype preprocessing:\n",
      "  Expression: (60660, 210)\n",
      "  Methylation: (212863, 210)\n",
      "  Copy number: (56646, 210)\n",
      "  Protein: (457, 210)\n",
      "  Phenotype: (210, 78)\n",
      "  Subtypes: 210\n",
      "  Common samples: 210\n"
     ]
    }
   ],
   "source": [
    "# Extract subtypes for the common samples\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create mapping to encode subtype classes\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"\\nSubtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"  {encoded}: {subtype}\")\n",
    "\n",
    "# Converted to pandas Series to easily handle the index\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nEncoded subtype distribution:\")\n",
    "print(subtype_encoded.value_counts().sort_index())\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "if missing_subtypes > 0:\n",
    "    valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "    print(f\"\\nUpdating common samples from {len(common_samples)} to {len(valid_samples)} (removed samples with missing subtypes)\")\n",
    "\n",
    "    expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "    methylation_scaled = methylation_scaled[valid_samples]\n",
    "    copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "    protein_scaled = protein_scaled[valid_samples]\n",
    "    subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "    \n",
    "    common_samples = valid_samples\n",
    "print()\n",
    "print(f\"Final data shapes after phenotype preprocessing:\")\n",
    "print(f\"  Expression: {expression_data_scaled.shape}\")\n",
    "print(f\"  Methylation: {methylation_scaled.shape}\")\n",
    "print(f\"  Copy number: {copy_number_scaled.shape}\")\n",
    "print(f\"  Protein: {protein_scaled.shape}\")\n",
    "print(f\"  Phenotype: {phenotype_data_clean.shape}\")\n",
    "print(f\"  Subtypes: {len(subtype_encoded)}\")\n",
    "print(f\"  Common samples: {len(common_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55b85c",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508448c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "# expression_data_scaled.to_csv(\"processed_expression.csv\")\n",
    "# methylation_scaled.to_csv(\"processed_methylation.csv\")\n",
    "# copy_number_scaled.to_csv(\"processed_cnv.csv\")\n",
    "# protein_scaled.to_csv(\"processed_protein.csv\")\n",
    "# subtype_encoded.to_csv(\"subtype_labels.csv\")\n",
    "\n",
    "# save subtype mapping\n",
    "# subtype_mapping_df = pd.DataFrame(list(subtype_mapping.items()), columns=['subtype_name', 'encoded_label'])\n",
    "# subtype_mapping_df.to_csv(\"subtype_mapping_with_protein.csv\", index=False)\n",
    "\n",
    "# print(f\"\\nFinal data shapes:\")\n",
    "# print(f\"Expression: {expression_data_scaled.shape}\")\n",
    "# print(f\"Methylation: {methylation_scaled.shape}\")\n",
    "# print(f\"Copy number: {copy_number_scaled.shape}\")\n",
    "# print(f\"Protein: {protein_scaled.shape}\")\n",
    "# print(f\"Subtypes: {len(subtype_encoded)}\")\n",
    "# print(f\"Subtype classes: {len(label_encoder.classes_)}\")\n",
    "# print(\"\\nProcessed data saved to CSV files:\")\n",
    "# print(\"- processed_expression.csv\")\n",
    "# print(\"- processed_methylation.csv\") \n",
    "# print(\"- processed_protein.csv\")\n",
    "# print(\"- processed_cnv.csv\")\n",
    "# print(\"- subtype_labels.csv\")\n",
    "# print(\"- subtype_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: (60660, 210)\n",
      "Methylation: (212863, 210)\n",
      "Copy Number: (56646, 210)\n",
      "Protein: (457, 210)\n",
      "Phenotype: (210, 78)\n",
      "Subtype labels: (210,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expression:\", expression_data_scaled.shape)\n",
    "print(\"Methylation:\", methylation_scaled.shape)\n",
    "print(\"Copy Number:\", copy_number_scaled.shape)\n",
    "print(\"Protein:\", protein_scaled.shape)\n",
    "print(\"Phenotype:\", phenotype_data_clean.shape)\n",
    "print(\"Subtype labels:\", subtype_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2832e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    TCGA-MB-A5YA-01A  TCGA-X6-A7WD-01A  TCGA-DX-AB3C-01A  \\\n",
      "Ensembl_ID                                                                 \n",
      "ENSG00000000003.15         -0.991605         -0.467354          0.135911   \n",
      "ENSG00000000005.6           0.279301         -0.447155         -0.502103   \n",
      "ENSG00000000419.13         -0.409478          0.048320         -0.923084   \n",
      "ENSG00000000457.14         -0.598295          0.514173         -0.287709   \n",
      "ENSG00000000460.17         -0.968116          0.617331         -0.827791   \n",
      "\n",
      "                    TCGA-DX-A3M1-01A  TCGA-DX-A48O-01A  \n",
      "Ensembl_ID                                              \n",
      "ENSG00000000003.15          0.606595         -1.274259  \n",
      "ENSG00000000005.6           0.440239          0.848149  \n",
      "ENSG00000000419.13          0.291095         -0.470558  \n",
      "ENSG00000000457.14         -0.434324          0.435434  \n",
      "ENSG00000000460.17          0.313320          0.085932  \n",
      "                       TCGA-MB-A5YA-01A  TCGA-X6-A7WD-01A  TCGA-DX-AB3C-01A  \\\n",
      "Composite Element REF                                                         \n",
      "cg00000292                     1.284522          0.906714         -2.567639   \n",
      "cg00000321                     0.384706          1.366586         -1.539287   \n",
      "cg00000363                     1.030796          1.927891         -1.246740   \n",
      "cg00000924                     0.773197          0.278779          0.308735   \n",
      "cg00001099                    -0.715214         -0.947329          0.984623   \n",
      "\n",
      "                       TCGA-DX-A3M1-01A  TCGA-DX-A48O-01A  \n",
      "Composite Element REF                                      \n",
      "cg00000292                     0.517455          1.167764  \n",
      "cg00000321                    -0.519599          0.536600  \n",
      "cg00000363                     0.849718          0.653238  \n",
      "cg00000924                    -0.882893         -1.500308  \n",
      "cg00001099                    -0.777898          0.898806  \n",
      "                    TCGA-MB-A5YA-01A  TCGA-X6-A7WD-01A  TCGA-DX-AB3C-01A  \\\n",
      "Ensembl_ID                                                                 \n",
      "ENSG00000230021.10         -0.459033         -1.262340         -0.459033   \n",
      "ENSG00000237491.10         -0.456843         -1.269869         -0.456843   \n",
      "ENSG00000230092.7          -0.459033         -1.262340         -0.459033   \n",
      "ENSG00000177757.2          -0.459033         -1.262340         -0.459033   \n",
      "ENSG00000228794.10         -0.462963         -1.266453         -0.462963   \n",
      "\n",
      "                    TCGA-DX-A3M1-01A  TCGA-DX-A48O-01A  \n",
      "Ensembl_ID                                              \n",
      "ENSG00000230021.10         -0.459033         -1.262340  \n",
      "ENSG00000237491.10         -0.456843         -1.269869  \n",
      "ENSG00000230092.7          -0.459033         -1.262340  \n",
      "ENSG00000177757.2          -0.459033         -1.262340  \n",
      "ENSG00000228794.10         -0.462963         -1.266453  \n",
      "                TCGA-MB-A5YA-01A  TCGA-X6-A7WD-01A  TCGA-DX-AB3C-01A  \\\n",
      "peptide_target                                                         \n",
      "1433BETA               -0.008717         -0.699203         -1.065260   \n",
      "1433EPSILON            -0.564504         -0.192348         -0.784490   \n",
      "1433ZETA                0.621322         -0.324014         -0.437991   \n",
      "4EBP1                  -0.924978          1.350572          0.002684   \n",
      "4EBP1_pS65             -0.482108          1.869746         -0.719953   \n",
      "\n",
      "                TCGA-DX-A3M1-01A  TCGA-DX-A48O-01A  \n",
      "peptide_target                                      \n",
      "1433BETA               -0.553133          0.224320  \n",
      "1433EPSILON            -0.457681         -0.881100  \n",
      "1433ZETA                0.443311          1.846697  \n",
      "4EBP1                   0.236960         -1.436307  \n",
      "4EBP1_pS65             -1.224041          0.131981  \n",
      "sample\n",
      "TCGA-MB-A5YA-01A     3\n",
      "TCGA-X6-A7WD-01A     3\n",
      "TCGA-DX-AB3C-01A    11\n",
      "TCGA-DX-A3M1-01A     0\n",
      "TCGA-DX-A48O-01A     3\n",
      "Name: subtype_encoded, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(expression_data_scaled.iloc[:5, :5])  # First 5 rows/columns\n",
    "print(methylation_scaled.iloc[:5, :5])\n",
    "print(copy_number_scaled.iloc[:5, :5])\n",
    "print(protein_scaled.iloc[:5, :5])\n",
    "print(subtype_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e74e97",
   "metadata": {},
   "source": [
    "# Reduce Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004490f",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c2edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Initializing autoencoder for expr modality\n",
      "Data shape: (60660, 210) -> After transpose: torch.Size([210, 60660])\n",
      "Input dimension (features): 60660\n",
      "Index colomn shape: (210,)\n",
      "Index colomn shape: (210,)\n",
      "   Bottleneck shape: (210, 64)\n",
      "   Decoder shape: (210, 60660)\n",
      "\n",
      ">> Initializing autoencoder for meth modality\n",
      "Data shape: (212863, 210) -> After transpose: torch.Size([210, 212863])\n",
      "Input dimension (features): 212863\n",
      "Index colomn shape: (210,)\n",
      "Index colomn shape: (210,)\n",
      "   Bottleneck shape: (210, 64)\n",
      "   Decoder shape: (210, 212863)\n",
      "\n",
      ">> Initializing autoencoder for cnv modality\n",
      "Data shape: (56646, 210) -> After transpose: torch.Size([210, 56646])\n",
      "Input dimension (features): 56646\n",
      "Index colomn shape: (210,)\n",
      "Index colomn shape: (210,)\n",
      "   Bottleneck shape: (210, 64)\n",
      "   Decoder shape: (210, 56646)\n",
      "\n",
      ">> Initializing autoencoder for prot modality\n",
      "Data shape: (457, 210) -> After transpose: torch.Size([210, 457])\n",
      "Input dimension (features): 457\n",
      "Index colomn shape: (210,)\n",
      "Index colomn shape: (210,)\n",
      "   Bottleneck shape: (210, 64)\n",
      "   Decoder shape: (210, 457)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, latent_dim=64):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)  # Bottleneck representation\n",
    "        x_hat = self.decoder(z)  # Decoder representation\n",
    "        return x_hat, z\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Extract bottleneck representation\"\"\"\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Extract decoder representation\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "def extract_representations(model, tensor_data):\n",
    "    \"\"\"Extract bottleneck and decoder representations from trained autoencoder\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get bottleneck (latent) representation\n",
    "        bottleneck = model.encode(tensor_data)\n",
    "        # Get decoder representation (reconstructed features)\n",
    "        decoder_repr = model.decode(bottleneck)\n",
    "    return bottleneck.cpu().numpy(), decoder_repr.cpu().numpy()\n",
    "\n",
    "# Initialize autoencoders for each omics type (without training)\n",
    "omics_scaled = {\n",
    "    'expr': expression_data_scaled,\n",
    "    'meth': methylation_scaled,\n",
    "    'cnv': copy_number_scaled,\n",
    "    'prot': protein_scaled\n",
    "}\n",
    "\n",
    "# Store autoencoder models (to be trained later)\n",
    "autoencoder_models = {}\n",
    "bottleneck_embeds = {}\n",
    "decoder_embeds = {}\n",
    "\n",
    "for name, df in omics_scaled.items():\n",
    "    print(f\">> Initializing autoencoder for {name} modality\")\n",
    "\n",
    "    X = torch.tensor(df.values.T, dtype=torch.float32, device=device)  # (samples, features) -- Transpose to (features, samples)\n",
    "    input_dim = X.shape[1]\n",
    "    sample_ids = df.columns\n",
    "    \n",
    "    print(f\"Data shape: {df.shape} -> After transpose: {X.shape}\")\n",
    "    print(f\"Input dimension (features): {input_dim}\")\n",
    "    \n",
    "    # Initialize autoencoder\n",
    "    model = Autoencoder(\n",
    "        input_dim=input_dim, \n",
    "        hidden_dim=128,\n",
    "        latent_dim=64\n",
    "    ).to(device)\n",
    "    autoencoder_models[name] = model\n",
    "\n",
    "    bottleneck, decoder_repr = extract_representations(model, X)\n",
    "    \n",
    "    print(f\"Index colomn shape: {df.columns.shape}\")\n",
    "    bottleneck_embeds[name] = pd.DataFrame(\n",
    "        bottleneck,\n",
    "        index=sample_ids,  # Sample IDs\n",
    "        columns=[f\"{name}_bottleneck_{i}\" for i in range(bottleneck.shape[1])]\n",
    "    )\n",
    "    \n",
    "    print(f\"Index colomn shape: {df.columns.shape}\")\n",
    "    decoder_embeds[name] = pd.DataFrame(\n",
    "        decoder_repr,\n",
    "        index=sample_ids,  # Sample IDs\n",
    "        columns=[f\"{name}_decoder_{i}\" for i in range(decoder_repr.shape[1])]\n",
    "    )\n",
    "    \n",
    "    print(f\"   Bottleneck shape: {bottleneck_embeds[name].shape}\")\n",
    "    print(f\"   Decoder shape: {decoder_embeds[name].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create fusion models\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Creating Fusion Models\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# # Fusion Model 1: Using bottleneck representations\n",
    "# bottleneck_fusion = pd.concat(\n",
    "#     [bottleneck_embeds['expr'], bottleneck_embeds['meth'], \n",
    "#      bottleneck_embeds['cnv'], bottleneck_embeds['prot']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Fusion Model 2: Using decoder representations\n",
    "# decoder_fusion = pd.concat(\n",
    "#     [decoder_embeds['expr'], decoder_embeds['meth'], \n",
    "#      decoder_embeds['cnv'], decoder_embeds['prot']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# print(f\"Bottleneck fusion shape: {bottleneck_fusion.shape}\")\n",
    "# print(f\"Decoder fusion shape: {decoder_fusion.shape}\")\n",
    "\n",
    "# print(\"\\nFusion models created successfully!\")\n",
    "# print(\"Note: These use untrained autoencoders. Train the models first, then re-extract representations.\")\n",
    "\n",
    "# # Display sample data\n",
    "# print(f\"\\nBottleneck fusion sample:\")\n",
    "# print(bottleneck_fusion.head())\n",
    "\n",
    "# print(f\"\\nDecoder fusion sample:\")\n",
    "# print(decoder_fusion.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
