{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6b0332",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751acfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab1fb1",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ce09bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "Expression data: (60660, 265)\n",
      "Methylation data: (486427, 269)\n",
      "Copy number data: (60623, 248)\n",
      "Protein data: (487, 226)\n",
      "Phenotype data: (272, 78)\n"
     ]
    }
   ],
   "source": [
    "expression_data = pd.read_csv('TCGA-SARC.star_tpm.tsv', sep='\\t', index_col=0)  # Gene expression (TPM)\n",
    "methylation_data = pd.read_csv('TCGA-SARC.methylation450.tsv', sep='\\t', index_col=0)  # DNA methylation\n",
    "copy_number_data = pd.read_csv('TCGA-SARC.gene-level_absolute.tsv', sep='\\t', index_col=0)  # Gene-level copy number (ABSOLUTE)\n",
    "protein_data = pd.read_csv('TCGA-SARC.protein.tsv', sep='\\t', index_col=0)  # Protein expression\n",
    "\n",
    "try:\n",
    "    phenotype_data = pd.read_csv('TCGA-SARC.clinical.tsv', sep='\\t', index_col=0)\n",
    "except Exception as e:\n",
    "    print(\"Error while loading phenotype_data:\", e)\n",
    "    with open('TCGA-SARC.clinical.tsv', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                pd.read_csv(pd.compat.StringIO(line), sep='\\t')\n",
    "            except Exception as row_e:\n",
    "                print(f\"Error in line {i}: {row_e}\")\n",
    "    phenotype_data = pd.read_csv('TCGA-SARC.clinical.tsv', sep='\\t', index_col=0, on_bad_lines='skip')\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"Expression data: {expression_data.shape}\")\n",
    "print(f\"Methylation data: {methylation_data.shape}\")\n",
    "print(f\"Copy number data: {copy_number_data.shape}\")\n",
    "print(f\"Protein data: {protein_data.shape}\")\n",
    "print(f\"Phenotype data: {phenotype_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7372a",
   "metadata": {},
   "source": [
    "# Sample Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d1f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in phenotype data:\n",
      "days_to_birth.demographic                                      1\n",
      "year_of_birth.demographic                                      4\n",
      "days_to_death.demographic                                    170\n",
      "year_of_death.demographic                                    195\n",
      "entity_submitter_id.annotations                              254\n",
      "notes.annotations                                            254\n",
      "submitter_id.annotations                                     254\n",
      "classification.annotations                                   254\n",
      "entity_id.annotations                                        254\n",
      "created_datetime.annotations                                 254\n",
      "annotation_id.annotations                                    254\n",
      "entity_type.annotations                                      254\n",
      "updated_datetime.annotations                                 254\n",
      "case_id.annotations                                          254\n",
      "state.annotations                                            254\n",
      "category.annotations                                         254\n",
      "status.annotations                                           254\n",
      "case_submitter_id.annotations                                254\n",
      "days_to_last_follow_up.diagnoses                              77\n",
      "age_at_diagnosis.diagnoses                                     1\n",
      "year_of_diagnosis.diagnoses                                    4\n",
      "age_at_earliest_diagnosis.diagnoses.xena_derived               1\n",
      "age_at_earliest_diagnosis_in_years.diagnoses.xena_derived      1\n",
      "days_to_collection.samples                                     4\n",
      "pathology_report_uuid.samples                                  6\n",
      "annotations.samples                                          266\n",
      "dtype: int64\n",
      "\n",
      "Checking sample overlap between different omics data:\n",
      "Sample overlap:\n",
      "Expression samples: 265\n",
      "Methylation samples: 269\n",
      "CNV samples: 248\n",
      "Clinical samples: 272\n",
      "Protein samples: 226\n",
      "Common samples across all omics: 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in phenotype data:\")\n",
    "missing_values = phenotype_data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "print()\n",
    "print(\"Checking sample overlap between different omics data:\")\n",
    "\n",
    "samples_expression = set(expression_data.columns)\n",
    "samples_methylation = set(methylation_data.columns)\n",
    "samples_cnv = set(copy_number_data.columns)\n",
    "samples_clinical = set(phenotype_data.index)\n",
    "samples_protein = set(protein_data.columns)\n",
    "print(\"Sample overlap:\")\n",
    "print(f\"Expression samples: {len(samples_expression)}\")\n",
    "print(f\"Methylation samples: {len(samples_methylation)}\")\n",
    "print(f\"CNV samples: {len(samples_cnv)}\")\n",
    "print(f\"Clinical samples: {len(samples_clinical)}\")\n",
    "print(f\"Protein samples: {len(samples_protein)}\")\n",
    "\n",
    "# Find common samples across all omics\n",
    "common_samples = list(samples_expression.intersection(samples_methylation, samples_cnv, samples_clinical, samples_protein))\n",
    "print(f\"Common samples across all omics: {len(common_samples)}\")\n",
    "\n",
    "# Filter data to keep only common samples\n",
    "expression_data = expression_data[common_samples]\n",
    "methylation_data = methylation_data[common_samples]\n",
    "copy_number_data = copy_number_data[common_samples]\n",
    "protein_data = protein_data[common_samples]\n",
    "phenotype_data = phenotype_data.loc[common_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba21134",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f5c64",
   "metadata": {},
   "source": [
    "### Check Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476aee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values in expression data:\n",
      "No null values found in expression data.\n",
      "\n",
      "Checking for null values in methylation data:\n",
      "Methylation data contains 16814049 null values.\n",
      "\n",
      "Checking for null values in copy number data:\n",
      "Copy number data contains 855388 null values.\n",
      "Maximum CNV value: 7.0\n",
      "Minimum CNV value: 0.0\n",
      "\n",
      "Checking for null values in protein data:\n",
      "Protein data contains 6300 null values.\n",
      "\n",
      "Checking for null values in phenotype data:\n",
      "Phenotype data contains 3389 null values.\n"
     ]
    }
   ],
   "source": [
    "#Check for null values of expression data\n",
    "print(\"Checking for null values in expression data:\")\n",
    "null_expression = expression_data.isnull().sum().sum()\n",
    "if null_expression > 0:\n",
    "    print(f\"Expression data contains {null_expression} null values.\")\n",
    "else:   \n",
    "    print(\"No null values found in expression data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in methylation data\n",
    "print(\"Checking for null values in methylation data:\")\n",
    "null_methylation = methylation_data.isnull().sum().sum()\n",
    "if null_methylation > 0:\n",
    "    print(f\"Methylation data contains {null_methylation} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in methylation data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in copy number data\n",
    "print(\"Checking for null values in copy number data:\")\n",
    "null_copy_number = copy_number_data.isnull().sum().sum()\n",
    "if null_copy_number > 0:\n",
    "    print(f\"Copy number data contains {null_copy_number} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in copy number data.\")\n",
    "max_value = copy_number_data.max().max()\n",
    "min_value = copy_number_data.min().min()\n",
    "\n",
    "print(f\"Maximum CNV value: {max_value}\")\n",
    "print(f\"Minimum CNV value: {min_value}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in protein data\n",
    "print(\"Checking for null values in protein data:\")\n",
    "null_protein = protein_data.isnull().sum().sum()\n",
    "if null_protein > 0:\n",
    "    print(f\"Protein data contains {null_protein} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in protein data.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Check for null values in phenotype data\n",
    "print(\"Checking for null values in phenotype data:\")\n",
    "null_phenotype = phenotype_data.isnull().sum().sum()\n",
    "if null_phenotype > 0:\n",
    "    print(f\"Phenotype data contains {null_phenotype} null values.\")\n",
    "else:\n",
    "    print(\"No null values found in phenotype data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8d1a5",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb72df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Log2 transform\n",
    "expression_data_log = np.log2(expression_data + 1)\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_expr = StandardScaler()\n",
    "expression_data_scaled = pd.DataFrame(\n",
    "    scaler_expr.fit_transform(expression_data_log.T).T,\n",
    "    index=expression_data_log.index,\n",
    "    columns=expression_data_log.columns\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "# Methylation data preprocessing -------------------------------------------------->\n",
    "\n",
    "# Droping probes with more than 10% missing values \n",
    "methylation_data = methylation_data.dropna(thresh=0.9 * methylation_data.shape[1], axis=0)\n",
    "\n",
    "# fill na with probe wise median\n",
    "methylation_data = methylation_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "\n",
    "# Remove low-variance methylation probes\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "methylation_filtered = pd.DataFrame(\n",
    "    selector.fit_transform(methylation_data.T).T,\n",
    "    index=methylation_data.index[selector.get_support()],\n",
    "    columns=methylation_data.columns\n",
    ")\n",
    "\n",
    "# Z-score standardization\n",
    "scaler_meth = StandardScaler()\n",
    "methylation_scaled = pd.DataFrame(\n",
    "    scaler_meth.fit_transform(methylation_filtered.T).T,\n",
    "    index=methylation_filtered.index,\n",
    "    columns=methylation_filtered.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Copy number data preprocessing -------------------------------------------------->\n",
    "\n",
    "\n",
    "# Drop genes with >20% missing values\n",
    "gene_missing_threshold = 0.2\n",
    "copy_number_data_filtered = copy_number_data.loc[\n",
    "    copy_number_data.isnull().mean(axis=1) < gene_missing_threshold\n",
    "]\n",
    "\n",
    "# filling null values with gene-wise median\n",
    "copy_number_imputed = copy_number_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_cnv = StandardScaler()\n",
    "copy_number_scaled = pd.DataFrame(\n",
    "    scaler_cnv.fit_transform(copy_number_imputed.T).T,\n",
    "    index=copy_number_imputed.index,\n",
    "    columns=copy_number_imputed.columns\n",
    ")\n",
    "\n",
    "\n",
    "# Protein data preprocessing ------------------------------------------------------>\n",
    "\n",
    "# Drop proteins with >20% missing values\n",
    "protein_missing_threshold = 0.3\n",
    "protein_data_filtered = protein_data.loc[\n",
    "    protein_data.isnull().mean(axis=1) < protein_missing_threshold\n",
    "]\n",
    "# filling null values with protein-wise median\n",
    "protein_imputed = protein_data_filtered.apply(\n",
    "    lambda row: row.fillna(row.median()), axis=1\n",
    ")\n",
    "\n",
    "# Standardize across samples\n",
    "scaler_protein = StandardScaler()\n",
    "protein_scaled = pd.DataFrame(\n",
    "    scaler_protein.fit_transform(protein_imputed.T).T,\n",
    "    index=protein_imputed.index,\n",
    "    columns=protein_imputed.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739bc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'primary_diagnosis.diagnoses' as the subtype column\n",
      "Subtype distribution:\n",
      "primary_diagnosis.diagnoses\n",
      "Leiomyosarcoma, NOS                        76\n",
      "Dedifferentiated liposarcoma               49\n",
      "Undifferentiated sarcoma                   32\n",
      "Fibromyxosarcoma                           20\n",
      "Malignant fibrous histiocytoma             11\n",
      "Malignant peripheral nerve sheath tumor     9\n",
      "Synovial sarcoma, spindle cell              4\n",
      "Giant cell sarcoma                          3\n",
      "Pleomorphic liposarcoma                     2\n",
      "Synovial sarcoma, NOS                       1\n",
      "Liposarcoma, well differentiated            1\n",
      "Synovial sarcoma, biphasic                  1\n",
      "Myxoid leiomyosarcoma                       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in subtype column: 0\n",
      "No missing subtypes found\n"
     ]
    }
   ],
   "source": [
    "# Phenotype data preprocessing -------------------------------------------------->\n",
    "\n",
    "subtype_column = 'primary_diagnosis.diagnoses'\n",
    "print(f\"Using '{subtype_column}' as the subtype column\")\n",
    "print(f\"Subtype distribution:\\n{phenotype_data[subtype_column].value_counts()}\")\n",
    "print()\n",
    "\n",
    "# Checking missing values in the subtype column\n",
    "missing_subtypes = phenotype_data[subtype_column].isnull().sum()\n",
    "print(f\"Missing values in subtype column: {missing_subtypes}\")\n",
    "\n",
    "if missing_subtypes > 0:\n",
    "    phenotype_data_clean = phenotype_data.dropna(subset=[subtype_column])\n",
    "    print(f\"Removed {missing_subtypes} samples with missing subtypes\")\n",
    "    print(f\"Remaining samples: {len(phenotype_data_clean)}\")\n",
    "else:\n",
    "    phenotype_data_clean = phenotype_data.copy()\n",
    "    print(\"No missing subtypes found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5a9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtype encoding mapping:\n",
      "  0: Dedifferentiated liposarcoma\n",
      "  1: Fibromyxosarcoma\n",
      "  2: Giant cell sarcoma\n",
      "  3: Leiomyosarcoma, NOS\n",
      "  4: Liposarcoma, well differentiated\n",
      "  5: Malignant fibrous histiocytoma\n",
      "  6: Malignant peripheral nerve sheath tumor\n",
      "  7: Myxoid leiomyosarcoma\n",
      "  8: Pleomorphic liposarcoma\n",
      "  9: Synovial sarcoma, NOS\n",
      "  10: Synovial sarcoma, biphasic\n",
      "  11: Synovial sarcoma, spindle cell\n",
      "  12: Undifferentiated sarcoma\n",
      "\n",
      "Encoded subtype distribution:\n",
      "subtype_encoded\n",
      "0     49\n",
      "1     20\n",
      "2      3\n",
      "3     76\n",
      "4      1\n",
      "5     11\n",
      "6      9\n",
      "7      1\n",
      "8      2\n",
      "9      1\n",
      "10     1\n",
      "11     4\n",
      "12    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final data shapes after phenotype preprocessing:\n",
      "  Expression: (60660, 210)\n",
      "  Methylation: (212863, 210)\n",
      "  Copy number: (56646, 210)\n",
      "  Protein: (457, 210)\n",
      "  Phenotype: (210, 78)\n",
      "  Subtypes: 210\n",
      "  Common samples: 210\n"
     ]
    }
   ],
   "source": [
    "# Extract subtypes for the common samples\n",
    "subtypes = phenotype_data_clean[subtype_column]\n",
    "\n",
    "# Encode subtypes as numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "subtype_encoded = label_encoder.fit_transform(subtypes)\n",
    "\n",
    "# Create mapping to encode subtype classes\n",
    "subtype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"\\nSubtype encoding mapping:\")\n",
    "for subtype, encoded in subtype_mapping.items():\n",
    "    print(f\"  {encoded}: {subtype}\")\n",
    "\n",
    "# Converted to pandas Series to easily handle the index\n",
    "subtype_encoded = pd.Series(subtype_encoded, index=subtypes.index, name='subtype_encoded')\n",
    "\n",
    "print(f\"\\nEncoded subtype distribution:\")\n",
    "print(subtype_encoded.value_counts().sort_index())\n",
    "\n",
    "# Update common samples with available subtypes\n",
    "if missing_subtypes > 0:\n",
    "    valid_samples = list(set(common_samples).intersection(set(phenotype_data_clean.index)))\n",
    "    print(f\"\\nUpdating common samples from {len(common_samples)} to {len(valid_samples)} (removed samples with missing subtypes)\")\n",
    "\n",
    "    expression_data_scaled = expression_data_scaled[valid_samples]\n",
    "    methylation_scaled = methylation_scaled[valid_samples]\n",
    "    copy_number_scaled = copy_number_scaled[valid_samples]\n",
    "    protein_scaled = protein_scaled[valid_samples]\n",
    "    subtype_encoded = subtype_encoded.loc[valid_samples]\n",
    "    \n",
    "    common_samples = valid_samples\n",
    "print()\n",
    "print(f\"Final data shapes after phenotype preprocessing:\")\n",
    "print(f\"  Expression: {expression_data_scaled.shape}\")\n",
    "print(f\"  Methylation: {methylation_scaled.shape}\")\n",
    "print(f\"  Copy number: {copy_number_scaled.shape}\")\n",
    "print(f\"  Protein: {protein_scaled.shape}\")\n",
    "print(f\"  Phenotype: {phenotype_data_clean.shape}\")\n",
    "print(f\"  Subtypes: {len(subtype_encoded)}\")\n",
    "print(f\"  Common samples: {len(common_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55b85c",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508448c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "# expression_data_scaled.to_csv(\"processed_expression.csv\")\n",
    "# methylation_scaled.to_csv(\"processed_methylation.csv\")\n",
    "# copy_number_scaled.to_csv(\"processed_cnv.csv\")\n",
    "# protein_scaled.to_csv(\"processed_protein.csv\")\n",
    "# phenotype_data_clean.to_csv(\"processed_phenotype.csv\")\n",
    "# subtype_encoded.to_csv(\"subtype_labels.csv\")\n",
    "\n",
    "\n",
    "# save subtype mapping\n",
    "# subtype_mapping_df = pd.DataFrame(list(subtype_mapping.items()), columns=['subtype_name', 'encoded_label'])\n",
    "# subtype_mapping_df.to_csv(\"subtype_mapping_with_protein.csv\", index=False)\n",
    "\n",
    "# print(f\"\\nFinal data shapes:\")\n",
    "# print(f\"Expression: {expression_data_scaled.shape}\")\n",
    "# print(f\"Methylation: {methylation_scaled.shape}\")\n",
    "# print(f\"Copy number: {copy_number_scaled.shape}\")\n",
    "# print(f\"Protein: {protein_scaled.shape}\")\n",
    "# print(f\"Subtypes: {len(subtype_encoded)}\")\n",
    "# print(f\"Subtype classes: {len(label_encoder.classes_)}\")\n",
    "# print(\"\\nProcessed data saved to CSV files:\")\n",
    "# print(\"- processed_expression.csv\")\n",
    "# print(\"- processed_methylation.csv\") \n",
    "# print(\"- processed_protein.csv\")\n",
    "# print(\"- processed_cnv.csv\")\n",
    "# print(\"- subtype_labels.csv\")\n",
    "# print(\"- subtype_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: (60660, 210)\n",
      "Methylation: (212863, 210)\n",
      "Copy Number: (56646, 210)\n",
      "Subtype labels: (210,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expression:\", expression_data_scaled.shape)\n",
    "print(\"Methylation:\", methylation_scaled.shape)\n",
    "print(\"Copy Number:\", copy_number_scaled.shape)\n",
    "print(\"Protein:\", protein_scaled.shape)\n",
    "print(\"Phenotype:\", phenotype_data_clean.shape)\n",
    "print(\"Subtype labels:\", subtype_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2832e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    TCGA-DX-A6B9-01A  TCGA-DX-A8BR-01A  TCGA-DX-A1L3-01A  \\\n",
      "Ensembl_ID                                                                 \n",
      "ENSG00000000003.15         -0.469188         -2.807430         -0.163443   \n",
      "ENSG00000000005.6           2.268745          0.226222          0.660750   \n",
      "ENSG00000000419.13         -0.519179          0.148284         -0.280435   \n",
      "ENSG00000000457.14          0.329740          1.138170          2.741732   \n",
      "ENSG00000000460.17         -1.261882          0.898457          1.845504   \n",
      "\n",
      "                    TCGA-Z4-AAPF-01A  TCGA-DX-A7ET-01A  \n",
      "Ensembl_ID                                              \n",
      "ENSG00000000003.15         -0.104785         -0.504571  \n",
      "ENSG00000000005.6           1.328134         -1.333194  \n",
      "ENSG00000000419.13         -1.087689         -1.117240  \n",
      "ENSG00000000457.14         -0.967435         -2.767352  \n",
      "ENSG00000000460.17         -1.096206         -2.129919  \n",
      "                       TCGA-DX-A6B9-01A  TCGA-DX-A8BR-01A  TCGA-DX-A1L3-01A  \\\n",
      "Composite Element REF                                                         \n",
      "cg00000292                    -1.595703         -0.843114          0.746048   \n",
      "cg00000321                    -0.960641          0.000776         -0.946071   \n",
      "cg00000363                    -0.984512          1.860467          1.032481   \n",
      "cg00000924                     0.439612          0.293287          0.882913   \n",
      "cg00001099                     0.239465          0.517891          0.749281   \n",
      "\n",
      "                       TCGA-Z4-AAPF-01A  TCGA-DX-A7ET-01A  \n",
      "Composite Element REF                                      \n",
      "cg00000292                    -1.827736          1.180997  \n",
      "cg00000321                    -1.440928         -0.321928  \n",
      "cg00000363                    -0.876451         -0.068859  \n",
      "cg00000924                     0.564531          0.461829  \n",
      "cg00001099                     1.028789         -0.329014  \n",
      "                    TCGA-DX-A6B9-01A  TCGA-DX-A8BR-01A  TCGA-DX-A1L3-01A  \\\n",
      "Ensembl_ID                                                                 \n",
      "ENSG00000230021.10         -0.459033         -0.459033         -0.459033   \n",
      "ENSG00000237491.10         -0.456843         -0.456843         -0.456843   \n",
      "ENSG00000230092.7          -0.459033         -0.459033         -0.459033   \n",
      "ENSG00000177757.2          -0.459033         -0.459033         -0.459033   \n",
      "ENSG00000228794.10         -0.462963         -0.462963         -0.462963   \n",
      "\n",
      "                    TCGA-Z4-AAPF-01A  TCGA-DX-A7ET-01A  \n",
      "Ensembl_ID                                              \n",
      "ENSG00000230021.10         -0.459033          0.344275  \n",
      "ENSG00000237491.10         -0.456843          0.356183  \n",
      "ENSG00000230092.7          -0.459033          0.344275  \n",
      "ENSG00000177757.2          -0.459033          0.344275  \n",
      "ENSG00000228794.10         -0.462963          0.340527  \n",
      "sample\n",
      "TCGA-DX-A6B9-01A     3\n",
      "TCGA-DX-A8BR-01A     5\n",
      "TCGA-DX-A1L3-01A     0\n",
      "TCGA-Z4-AAPF-01A     9\n",
      "TCGA-DX-A7ET-01A    12\n",
      "Name: subtype_encoded, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(expression_data_scaled.iloc[:5, :5])  # First 5 rows/columns\n",
    "print(methylation_scaled.iloc[:5, :5])\n",
    "print(copy_number_scaled.iloc[:5, :5])\n",
    "print(protein_scaled.iloc[:5, :5])\n",
    "print(subtype_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97643d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Label Encoding for Categorical Phenotype Variables\n",
    "# print(\"LABEL ENCODING FOR PHENOTYPE DATA\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# # Separate numeric and categorical columns\n",
    "# numeric_cols = phenotype_data_clean2.select_dtypes(include=[np.number]).columns\n",
    "# categorical_cols = phenotype_data_clean2.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# print(f\"üìä Phenotype Data Analysis:\")\n",
    "# print(f\"   Total columns: {len(phenotype_data_clean2.columns)}\")\n",
    "# print(f\"   Numeric columns: {len(numeric_cols)}\")\n",
    "# print(f\"   Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "# print(f\"\\nüìã Numeric columns:\")\n",
    "# for col in numeric_cols:\n",
    "#     print(f\"   - {col}\")\n",
    "\n",
    "# # print(f\"\\nüìã Categorical columns:\")\n",
    "# # for col in categorical_cols:\n",
    "# #     unique_vals = phenotype_data_clean2[col].nunique()\n",
    "# #     print(f\"   - {col} ({unique_vals} unique values)\")\n",
    "\n",
    "# # Create encoded phenotype dataset\n",
    "# print(f\"\\nüîÑ Applying Label Encoding to categorical variables...\")\n",
    "# phenotype_encoded = phenotype_data_clean2[numeric_cols].copy()\n",
    "\n",
    "# # Encode categorical columns (only if they have reasonable number of categories)\n",
    "# encoders = {}\n",
    "# max_categories = 20  # Only encode if less than 20 unique values\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     n_unique = phenotype_data_clean2[col].nunique()\n",
    "    \n",
    "#     # Skip columns with too many unique values (likely IDs)\n",
    "#     if n_unique >= max_categories:\n",
    "#         print(f\"   ‚ö†Ô∏è  Skipping '{col}' ({n_unique} unique values - likely an ID column)\")\n",
    "#         continue\n",
    "    \n",
    "#     # Skip columns with all missing or single value\n",
    "#     if n_unique <= 1:\n",
    "#         print(f\"   ‚ö†Ô∏è  Skipping '{col}' ({n_unique} unique value - no information)\")\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         le = LabelEncoder()\n",
    "#         # Handle missing values by converting to string first\n",
    "#         phenotype_encoded[f\"{col}_encoded\"] = le.fit_transform(\n",
    "#             phenotype_data_clean2[col].fillna('Missing').astype(str)\n",
    "#         )\n",
    "#         encoders[col] = le\n",
    "#         print(f\"   ‚úÖ Encoded '{col}' ‚Üí '{col}_encoded' ({n_unique} categories)\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"   ‚ùå Failed to encode '{col}': {str(e)}\")\n",
    "\n",
    "# print(f\"\\nüìä Encoded Phenotype Data Summary:\")\n",
    "# print(f\"   Original shape: {phenotype_data_clean2.shape}\")\n",
    "# print(f\"   Encoded shape: {phenotype_encoded.shape}\")\n",
    "# print(f\"   Original features: {len(phenotype_data_clean2.columns)}\")\n",
    "# print(f\"   Encoded features: {len(phenotype_encoded.columns)}\")\n",
    "# print(f\"   Added encoded features: {len(phenotype_encoded.columns) - len(numeric_cols)}\")\n",
    "\n",
    "# # Check for missing values\n",
    "# print(f\"\\nüîç Missing Values Check:\")\n",
    "# missing_counts = phenotype_encoded.isnull().sum()\n",
    "# if missing_counts.sum() == 0:\n",
    "#     print(f\"   ‚úÖ No missing values in encoded phenotype data\")\n",
    "# else:\n",
    "#     print(f\"   ‚ö†Ô∏è  Found {missing_counts.sum()} missing values:\")\n",
    "#     for col in missing_counts[missing_counts > 0].index:\n",
    "#         print(f\"      - {col}: {missing_counts[col]} missing\")\n",
    "\n",
    "# # Handle missing values strategically\n",
    "# print(f\"\\nüîÑ Handling missing values in phenotype data...\")\n",
    "\n",
    "# # Impute age/birth/diagnosis columns with median (small number of missing)\n",
    "# age_related_cols = [col for col in phenotype_encoded.columns \n",
    "#                     if any(x in col.lower() for x in ['age', 'birth', 'diagnosis', 'collection'])\n",
    "#                     and 'death' not in col.lower()]\n",
    "\n",
    "# imputed_count = 0\n",
    "# for col in age_related_cols:\n",
    "#     if phenotype_encoded[col].isnull().any():\n",
    "#         n_missing = phenotype_encoded[col].isnull().sum()\n",
    "#         median_val = phenotype_encoded[col].median()\n",
    "#         phenotype_encoded[col].fillna(median_val, inplace=True)\n",
    "#         imputed_count += n_missing\n",
    "#         if n_missing > 0:\n",
    "#             print(f\"   ‚úÖ Imputed {n_missing} values in '{col}' with median\")\n",
    "\n",
    "# # Fill remaining missing values (death/annotation columns) with 0\n",
    "# # These represent \"no event\" or \"no data\" which is informative\n",
    "# remaining_missing = phenotype_encoded.isnull().sum().sum()\n",
    "# if remaining_missing > 0:\n",
    "#     print(f\"\\n   üìù Filling {remaining_missing} remaining missing values with 0 (informative missingness)\")\n",
    "#     phenotype_encoded.fillna(0, inplace=True)\n",
    "\n",
    "# print(f\"\\n‚úÖ Missing value handling completed!\")\n",
    "# print(f\"   Imputed: {imputed_count} values (age/diagnosis related)\")\n",
    "# print(f\"   Filled with 0: {remaining_missing} values (death/annotation columns)\")\n",
    "# print(f\"   Final missing values: {phenotype_encoded.isnull().sum().sum()}\")\n",
    "\n",
    "# # Store the encoded phenotype for later use\n",
    "# phenotype_data_encoded = phenotype_encoded.copy()\n",
    "# # phenotype_data_encoded.to_csv(\"phenotype_data_encoded.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
